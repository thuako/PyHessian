{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "Authors: Zhewei Yao <https://github.com/yaozhewei>, Amir Gholami <http://amirgholami.org/>\n",
    "\n",
    "\n",
    "This tutorial shows how to compute the Hessian information using (randomized) numerical linear algebra for both explicit Hessian (the matrix is given) as well as implicit Hessian (the matrix is ungiven).\n",
    "\n",
    "We'll start by doing the necessary imports:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import numpy as np\n",
    "import torch \n",
    "from torchvision import datasets, transforms\n",
    "from utils import * # get the dataset\n",
    "from pyhessian import hessian\n",
    "from pyhessian.hessian_with_activation import hessian_with_activation # Hessian computation\n",
    "from density_plot import get_esd_plot # ESD plot\n",
    "from pytorchcv.model_provider import get_model as ptcv_get_model # model\n",
    "from pyhessian.utils import group_product\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "# enable cuda devices\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "\n",
    "# device = torch.device(\"cuda:0,1\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "# get the model \n",
    "model = ptcv_get_model(\"resnet20_cifar10\", pretrained=True)\n",
    "\n",
    "# change the model to eval mode to disable running stats upate\n",
    "model.eval()\n",
    "\n",
    "\n",
    "# create loss function\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# get dataset \n",
    "train_loader, test_loader = getData(train_bs=20, train_length=0.02)\n",
    "\n",
    "model = model.cuda()\n",
    "\n",
    "# to print batch size and the number of batch\n",
    "for inputs, targets in train_loader:\n",
    "    break;\n",
    "print(len(train_loader))    \n",
    "print(len(inputs))\n",
    "\n",
    "# make hessian object\n",
    "hessian_comp = hessian_with_activation(model, criterion, dataloader=train_loader, cuda=True)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Files already downloaded and verified\n",
      "50\n",
      "20\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "target = \"weight\"\n",
    "\n",
    "if target == \"input\":\n",
    "    # insert forward and backword hook in model\n",
    "    hessian_comp.insert_hook(\"conv\") # insert hook to module which name ends with \"conv\"\n",
    "\n",
    "    # compute input hessian from full dataset\n",
    "    act_trace = hessian_comp.trace_activ(maxIter=2, tol=1e-6)\n",
    "    print(np.mean(act_trace, axis=0))\n",
    "elif target == \"weight\":\n",
    "    weight_trace = hessian_comp.trace(maxIter=1, param_name='conv.weight')\n",
    "    print(np.mean(weight_trace, axis=0))\n",
    "\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "trace had not been converge\n",
      "[ 1.65418892e+01  6.69527054e+01  1.22185196e+02  3.60268745e+01\n",
      " -3.12565994e+00  8.31134491e+01  1.61412659e+01  1.71913330e+02\n",
      "  1.87712421e+01  2.60156670e+01  1.55261860e+01 -6.51743174e+00\n",
      "  2.11751614e+01 -5.25889540e+00  6.81667328e+01  1.59252289e+02\n",
      "  1.00606794e+01 -9.92853642e-02  2.15795059e+01  3.80902596e+01\n",
      " -3.12092743e+01]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# to check hooked layer, param size and grad size\n",
    "hessian_comp.get_activ_rand_v(show_layer=True, dont_reset=True) # if you not remove remark of get_same_size_activ_grad, show_layer option not work\n",
    "\n",
    "# print hooked layer , param size and grad size\n",
    "for layer in hessian_comp.activation_grads.keys():\n",
    "    has_grad = hessian_comp.activation_grads[layer][0] #.require_grad()\n",
    "    # print(dir(has_grad))\n",
    "    if (has_grad is not None):\n",
    "        print(f\"*** {layer} : {has_grad.grad_fn}\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "append features.stage1.unit1.body.conv1.conv, active size : torch.Size([20, 16, 32, 32]), active grad size : torch.Size([20, 16, 32, 32])\n",
      "append features.stage1.unit1.body.conv2.conv, active size : torch.Size([20, 16, 32, 32]), active grad size : torch.Size([20, 16, 32, 32])\n",
      "append features.stage1.unit2.body.conv1.conv, active size : torch.Size([20, 16, 32, 32]), active grad size : torch.Size([20, 16, 32, 32])\n",
      "append features.stage1.unit2.body.conv2.conv, active size : torch.Size([20, 16, 32, 32]), active grad size : torch.Size([20, 16, 32, 32])\n",
      "append features.stage1.unit3.body.conv1.conv, active size : torch.Size([20, 16, 32, 32]), active grad size : torch.Size([20, 16, 32, 32])\n",
      "append features.stage1.unit3.body.conv2.conv, active size : torch.Size([20, 16, 32, 32]), active grad size : torch.Size([20, 16, 32, 32])\n",
      "append features.stage2.unit1.identity_conv.conv, active size : torch.Size([20, 16, 32, 32]), active grad size : torch.Size([20, 16, 32, 32])\n",
      "append features.stage2.unit1.body.conv1.conv, active size : torch.Size([20, 16, 32, 32]), active grad size : torch.Size([20, 16, 32, 32])\n",
      "append features.stage2.unit1.body.conv2.conv, active size : torch.Size([20, 32, 16, 16]), active grad size : torch.Size([20, 32, 16, 16])\n",
      "append features.stage2.unit2.body.conv1.conv, active size : torch.Size([20, 32, 16, 16]), active grad size : torch.Size([20, 32, 16, 16])\n",
      "append features.stage2.unit2.body.conv2.conv, active size : torch.Size([20, 32, 16, 16]), active grad size : torch.Size([20, 32, 16, 16])\n",
      "append features.stage2.unit3.body.conv1.conv, active size : torch.Size([20, 32, 16, 16]), active grad size : torch.Size([20, 32, 16, 16])\n",
      "append features.stage2.unit3.body.conv2.conv, active size : torch.Size([20, 32, 16, 16]), active grad size : torch.Size([20, 32, 16, 16])\n",
      "append features.stage3.unit1.identity_conv.conv, active size : torch.Size([20, 32, 16, 16]), active grad size : torch.Size([20, 32, 16, 16])\n",
      "append features.stage3.unit1.body.conv1.conv, active size : torch.Size([20, 32, 16, 16]), active grad size : torch.Size([20, 32, 16, 16])\n",
      "append features.stage3.unit1.body.conv2.conv, active size : torch.Size([20, 64, 8, 8]), active grad size : torch.Size([20, 64, 8, 8])\n",
      "append features.stage3.unit2.body.conv1.conv, active size : torch.Size([20, 64, 8, 8]), active grad size : torch.Size([20, 64, 8, 8])\n",
      "append features.stage3.unit2.body.conv2.conv, active size : torch.Size([20, 64, 8, 8]), active grad size : torch.Size([20, 64, 8, 8])\n",
      "append features.stage3.unit3.body.conv1.conv, active size : torch.Size([20, 64, 8, 8]), active grad size : torch.Size([20, 64, 8, 8])\n",
      "append features.stage3.unit3.body.conv2.conv, active size : torch.Size([20, 64, 8, 8]), active grad size : torch.Size([20, 64, 8, 8])\n",
      "*** features.stage3.unit3.body.conv2.conv : <CudnnConvolutionBackwardBackward object at 0x7ff68b171d30>\n",
      "*** features.stage3.unit3.body.conv1.conv : <CudnnConvolutionBackwardBackward object at 0x7ff68b1710a0>\n",
      "*** features.stage3.unit2.body.conv2.conv : <CudnnConvolutionBackwardBackward object at 0x7ff68b171f40>\n",
      "*** features.stage3.unit2.body.conv1.conv : <CudnnConvolutionBackwardBackward object at 0x7ff68b171b20>\n",
      "*** features.stage3.unit1.body.conv2.conv : <CudnnConvolutionBackwardBackward object at 0x7ff68b171670>\n",
      "*** features.stage3.unit1.body.conv1.conv : <CudnnConvolutionBackwardBackward object at 0x7ff68b171910>\n",
      "*** features.stage3.unit1.identity_conv : <NativeBatchNormBackwardBackward object at 0x7ff68b171730>\n",
      "*** features.stage3.unit1.identity_conv.conv : <CudnnConvolutionBackwardBackward object at 0x7ff68b171a90>\n",
      "*** features.stage2.unit3.body.conv2.conv : <CudnnConvolutionBackwardBackward object at 0x7ff7300a7fd0>\n",
      "*** features.stage2.unit3.body.conv1.conv : <CudnnConvolutionBackwardBackward object at 0x7ff7300a7610>\n",
      "*** features.stage2.unit2.body.conv2.conv : <CudnnConvolutionBackwardBackward object at 0x7ff68b1e7e80>\n",
      "*** features.stage2.unit2.body.conv1.conv : <CudnnConvolutionBackwardBackward object at 0x7ff68b228f40>\n",
      "*** features.stage2.unit1.body.conv2.conv : <CudnnConvolutionBackwardBackward object at 0x7ff73010dee0>\n",
      "*** features.stage2.unit1.body.conv1.conv : <CudnnConvolutionBackwardBackward object at 0x7ff6880590d0>\n",
      "*** features.stage2.unit1.identity_conv : <NativeBatchNormBackwardBackward object at 0x7ff688059190>\n",
      "*** features.stage2.unit1.identity_conv.conv : <CudnnConvolutionBackwardBackward object at 0x7ff688059250>\n",
      "*** features.stage1.unit3.body.conv2.conv : <CudnnConvolutionBackwardBackward object at 0x7ff688059310>\n",
      "*** features.stage1.unit3.body.conv1.conv : <CudnnConvolutionBackwardBackward object at 0x7ff6880593d0>\n",
      "*** features.stage1.unit2.body.conv2.conv : <CudnnConvolutionBackwardBackward object at 0x7ff688059490>\n",
      "*** features.stage1.unit2.body.conv1.conv : <CudnnConvolutionBackwardBackward object at 0x7ff688059550>\n",
      "*** features.stage1.unit1.body.conv2.conv : <CudnnConvolutionBackwardBackward object at 0x7ff688059610>\n",
      "*** features.stage1.unit1.body.conv1.conv : <CudnnConvolutionBackwardBackward object at 0x7ff6880596d0>\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# From this block, all codes are for debug\n",
    "from pyhessian.utils import *\n",
    "\n",
    "# to check grad and param in 1 batch backward\n",
    "device = hessian_comp.device\n",
    "hessian_comp.insert_hook_quant_module(\"quant_convbn\")\n",
    "for inputs, targets in hessian_comp.data:\n",
    "    hessian_comp.model.zero_grad()\n",
    "\n",
    "    hessian_comp.reset_reg_active()\n",
    "\n",
    "    outputs = hessian_comp.model(inputs.to(device))\n",
    "    loss = hessian_comp.criterion(outputs, targets.to(device))\n",
    "    loss.backward(create_graph=True)\n",
    "    break\n",
    "param, grad = get_params_grad(hessian_comp.model)\n",
    "\n",
    "for p, g in zip(param, grad):\n",
    "    print(p.size(), g.size(), g.grad_fn)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "\n",
    "# # print(hessian_comp.activations.keys())\n",
    "# print((hessian_comp.activation_grads[\"features.stage1.unit1.body.conv1.conv\"][0][0].size()))\n",
    "# print((hessian_comp.activations[\"features.stage1.unit1.body.conv1.conv\"][0][0].size()))\n",
    "# # print((hessian_comp.activations[\"features.stage1.unit1.body.conv1.conv\"][0][0].grad))\n",
    "# print((hessian_comp.activations[\"features.stage1.unit1.body.conv1.conv\"][0][0]))\n",
    "# print((hessian_comp.activation_grads[\"features.stage1.unit1.body.conv1.conv\"][0][0]))\n",
    "# # print((hessian_comp.activation_grads[\"features.stage1.unit1.body.conv1.conv\"][0][0].grad_fn.next_functions))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "for layer in hessian_comp.activations.keys():\n",
    "    input_size = torch.randint_like(hessian_comp.activations[layer][0][0], high=2, device=\"cuda\").size()\n",
    "    if hessian_comp.activation_grads[layer][0][0] is not None:\n",
    "        grad_size = hessian_comp.activation_grads[layer][0][0].size()\n",
    "    else:\n",
    "        grad_size = 1\n",
    "    # print(type(hessian_comp.activation_grads[layer][i][0]))\n",
    "    if(input_size != grad_size):\n",
    "        print(f\"************* {layer} not equal!! ************\")\n",
    "        print( input_size, grad_size, \"\\n\\n\")\n",
    "    else:\n",
    "        print(f\"************* {layer} ************\")\n",
    "        print( input_size, \"\\n\\n\")\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "************* features.init_block.conv ************\n",
      "torch.Size([5, 3, 32, 32]) 1 \n",
      "\n",
      "\n",
      "************* features.stage1.unit1.body.conv1.conv ************\n",
      "torch.Size([5, 16, 32, 32]) \n",
      "\n",
      "\n",
      "************* features.stage1.unit1.body.conv2.conv ************\n",
      "torch.Size([5, 16, 32, 32]) \n",
      "\n",
      "\n",
      "************* features.stage1.unit2.body.conv1.conv ************\n",
      "torch.Size([5, 16, 32, 32]) \n",
      "\n",
      "\n",
      "************* features.stage1.unit2.body.conv2.conv ************\n",
      "torch.Size([5, 16, 32, 32]) \n",
      "\n",
      "\n",
      "************* features.stage1.unit3.body.conv1.conv ************\n",
      "torch.Size([5, 16, 32, 32]) \n",
      "\n",
      "\n",
      "************* features.stage1.unit3.body.conv2.conv ************\n",
      "torch.Size([5, 16, 32, 32]) \n",
      "\n",
      "\n",
      "************* features.stage2.unit1.identity_conv.conv ************\n",
      "torch.Size([5, 16, 32, 32]) \n",
      "\n",
      "\n",
      "************* features.stage2.unit1.identity_conv ************\n",
      "torch.Size([5, 16, 32, 32]) torch.Size([5, 32, 16, 16]) \n",
      "\n",
      "\n",
      "************* features.stage2.unit1.body.conv1.conv ************\n",
      "torch.Size([5, 16, 32, 32]) \n",
      "\n",
      "\n",
      "************* features.stage2.unit1.body.conv2.conv ************\n",
      "torch.Size([5, 32, 16, 16]) \n",
      "\n",
      "\n",
      "************* features.stage2.unit2.body.conv1.conv ************\n",
      "torch.Size([5, 32, 16, 16]) \n",
      "\n",
      "\n",
      "************* features.stage2.unit2.body.conv2.conv ************\n",
      "torch.Size([5, 32, 16, 16]) \n",
      "\n",
      "\n",
      "************* features.stage2.unit3.body.conv1.conv ************\n",
      "torch.Size([5, 32, 16, 16]) \n",
      "\n",
      "\n",
      "************* features.stage2.unit3.body.conv2.conv ************\n",
      "torch.Size([5, 32, 16, 16]) \n",
      "\n",
      "\n",
      "************* features.stage3.unit1.identity_conv.conv ************\n",
      "torch.Size([5, 32, 16, 16]) \n",
      "\n",
      "\n",
      "************* features.stage3.unit1.identity_conv ************\n",
      "torch.Size([5, 32, 16, 16]) torch.Size([5, 64, 8, 8]) \n",
      "\n",
      "\n",
      "************* features.stage3.unit1.body.conv1.conv ************\n",
      "torch.Size([5, 32, 16, 16]) \n",
      "\n",
      "\n",
      "************* features.stage3.unit1.body.conv2.conv ************\n",
      "torch.Size([5, 64, 8, 8]) \n",
      "\n",
      "\n",
      "************* features.stage3.unit2.body.conv1.conv ************\n",
      "torch.Size([5, 64, 8, 8]) \n",
      "\n",
      "\n",
      "************* features.stage3.unit2.body.conv2.conv ************\n",
      "torch.Size([5, 64, 8, 8]) \n",
      "\n",
      "\n",
      "************* features.stage3.unit3.body.conv1.conv ************\n",
      "torch.Size([5, 64, 8, 8]) \n",
      "\n",
      "\n",
      "************* features.stage3.unit3.body.conv2.conv ************\n",
      "torch.Size([5, 64, 8, 8]) \n",
      "\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "\"\"\"\n",
    "hessian_comp.activations[\"features.stage3.unit2.activ\"] are saved inputs of each layer\n",
    "while executing trace and dataload_hv_product for loop. \n",
    "They listed by trace and dataload_hv_product for loop.\n",
    "\n",
    "Dim 1 of hessian_comp.activations[\"features.stage3.unit2.activ\"][0] means batch.\n",
    "\"\"\"\n",
    "# v = torch.randint_like(hessian_comp.activations[\"features.stage1.unit1.body.conv1.conv\"][0][0], high=2, device=\"cuda\")\n",
    "rand_vs = []\n",
    "activ_grads = []\n",
    "activs = []\n",
    "\n",
    "for layer in hessian_comp.activations.keys():\n",
    "    for i in range(len(hessian_comp.activations[layer])):\n",
    "        activ_element = hessian_comp.activations[layer][i][0]\n",
    "        grad_element = hessian_comp.activation_grads[layer][i][0]\n",
    "\n",
    "        if (grad_element is None):\n",
    "            continue\n",
    "        elif grad_element.size() != activ_element.size() :\n",
    "            continue\n",
    "        else:    \n",
    "            rand_vs.append(torch.randint_like(hessian_comp.activations[layer][i][0], high=2, device=\"cuda\"))\n",
    "            activ_grads.append(hessian_comp.activation_grads[layer][i][0])\n",
    "            activs.append(hessian_comp.activations[layer][i][0])\n",
    "\n",
    "\n",
    "Hv_list = []\n",
    "trace_list = []\n",
    "for (v, grad, activ) in zip(rand_vs, activ_grads, activs):\n",
    "    Hv = torch.autograd.grad(\n",
    "        grad, \n",
    "        activ, \n",
    "        grad_outputs=v, only_inputs=True, retain_graph=True)\n",
    "    Hv_list.append(Hv)\n",
    "    trace_list.append(group_product(Hv, v).cpu().item())\n",
    "\n",
    "print(trace_list)\n",
    "\n",
    "\n",
    "# Hv = torch.autograd.grad(\n",
    "#     hessian_comp.activation_grads[\"features.stage1.unit1.body.conv1.conv\"][0][0], \n",
    "#     hessian_comp.activations[\"features.stage1.unit1.body.conv1.conv\"][0][0], \n",
    "#     grad_outputs=v, only_inputs=True, retain_graph=False)\n",
    "\n",
    "\n",
    "\n",
    "# a = torch.autograd.grad(hessian_comp.activation_grads[\"features.stage3.unit2.activ\"][1][0], hessian_comp.activations[\"features.stage3.unit2.activ\"][1]) \n",
    "# print(hessian_comp.activations[\"features.stage3.unit2.activ\"][1].size())"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[0.2398936152458191, 0.2883727252483368, 0.06399604678153992, 2.021277904510498, 0.024379881098866463, 2.3017399311065674, 0.05182919651269913, 0.07555367797613144, 0.4853941798210144, 0.007302280515432358, 0.8529448509216309, 0.2646264433860779, 21.458599090576172, 0.010562198236584663, 0.03980473428964615, 3.2707457542419434, 1.180624008178711, 5.310753345489502, 2.88645339012146, 5.8211669921875]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "layer1 = \"features.stage1.unit1.body.conv1.conv\"\n",
    "\n",
    "tmp_v = torch.randint_like(hessian_comp.activations[layer1][0][0], high=2, device=\"cuda\")\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "layer2 = \"features.stage1.unit1.body.conv1.conv\"\n",
    "\n",
    "Hv = torch.autograd.grad(\n",
    "    hessian_comp.activation_grads[layer1][0][0], \n",
    "    hessian_comp.activations[layer2][0][0], \n",
    "    grad_outputs=tmp_v, only_inputs=True, retain_graph=True)\n",
    "\n",
    "\n",
    "\n",
    "print(group_product(Hv, tmp_v).cpu().item())\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.6590860486030579\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a07942d7ea83692363db5dfc5da1c415492af6053fd8e4436b93cdbac81289b7"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.11 64-bit ('torch17-cu11.0': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}