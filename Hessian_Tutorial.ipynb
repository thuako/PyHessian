{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "Authors: Zhewei Yao <https://github.com/yaozhewei>, Amir Gholami <http://amirgholami.org/>\n",
    "\n",
    "\n",
    "This tutorial shows how to compute the Hessian information using (randomized) numerical linear algebra for both explicit Hessian (the matrix is given) as well as implicit Hessian (the matrix is ungiven).\n",
    "\n",
    "We'll start by doing the necessary imports:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import numpy as np\n",
    "import torch \n",
    "from torchvision import datasets, transforms\n",
    "from utils import * # get the dataset\n",
    "from pyhessian import hessian\n",
    "from pyhessian.hessian_with_activation import hessian_with_activation # Hessian computation\n",
    "from density_plot import get_esd_plot # ESD plot\n",
    "from pytorchcv.model_provider import get_model as ptcv_get_model # model\n",
    "from pyhessian.utils import group_product\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "# enable cuda devices\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0,1\"\n",
    "\n",
    "# device = torch.device(\"cuda:0,1\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# get the model \n",
    "model = ptcv_get_model(\"resnet20_cifar10\", pretrained=True)\n",
    "\n",
    "# change the model to eval mode to disable running stats upate\n",
    "model.eval()\n"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "CIFARResNet(\n",
       "  (features): Sequential(\n",
       "    (init_block): ConvBlock(\n",
       "      (conv): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (activ): ReLU(inplace=True)\n",
       "    )\n",
       "    (stage1): Sequential(\n",
       "      (unit1): ResUnit(\n",
       "        (body): ResBlock(\n",
       "          (conv1): ConvBlock(\n",
       "            (conv): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (activ): ReLU(inplace=True)\n",
       "          )\n",
       "          (conv2): ConvBlock(\n",
       "            (conv): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (activ): ReLU(inplace=True)\n",
       "      )\n",
       "      (unit2): ResUnit(\n",
       "        (body): ResBlock(\n",
       "          (conv1): ConvBlock(\n",
       "            (conv): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (activ): ReLU(inplace=True)\n",
       "          )\n",
       "          (conv2): ConvBlock(\n",
       "            (conv): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (activ): ReLU(inplace=True)\n",
       "      )\n",
       "      (unit3): ResUnit(\n",
       "        (body): ResBlock(\n",
       "          (conv1): ConvBlock(\n",
       "            (conv): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (activ): ReLU(inplace=True)\n",
       "          )\n",
       "          (conv2): ConvBlock(\n",
       "            (conv): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (activ): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (stage2): Sequential(\n",
       "      (unit1): ResUnit(\n",
       "        (body): ResBlock(\n",
       "          (conv1): ConvBlock(\n",
       "            (conv): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (activ): ReLU(inplace=True)\n",
       "          )\n",
       "          (conv2): ConvBlock(\n",
       "            (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (identity_conv): ConvBlock(\n",
       "          (conv): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (activ): ReLU(inplace=True)\n",
       "      )\n",
       "      (unit2): ResUnit(\n",
       "        (body): ResBlock(\n",
       "          (conv1): ConvBlock(\n",
       "            (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (activ): ReLU(inplace=True)\n",
       "          )\n",
       "          (conv2): ConvBlock(\n",
       "            (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (activ): ReLU(inplace=True)\n",
       "      )\n",
       "      (unit3): ResUnit(\n",
       "        (body): ResBlock(\n",
       "          (conv1): ConvBlock(\n",
       "            (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (activ): ReLU(inplace=True)\n",
       "          )\n",
       "          (conv2): ConvBlock(\n",
       "            (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (activ): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (stage3): Sequential(\n",
       "      (unit1): ResUnit(\n",
       "        (body): ResBlock(\n",
       "          (conv1): ConvBlock(\n",
       "            (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (activ): ReLU(inplace=True)\n",
       "          )\n",
       "          (conv2): ConvBlock(\n",
       "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (identity_conv): ConvBlock(\n",
       "          (conv): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (activ): ReLU(inplace=True)\n",
       "      )\n",
       "      (unit2): ResUnit(\n",
       "        (body): ResBlock(\n",
       "          (conv1): ConvBlock(\n",
       "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (activ): ReLU(inplace=True)\n",
       "          )\n",
       "          (conv2): ConvBlock(\n",
       "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (activ): ReLU(inplace=True)\n",
       "      )\n",
       "      (unit3): ResUnit(\n",
       "        (body): ResBlock(\n",
       "          (conv1): ConvBlock(\n",
       "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (activ): ReLU(inplace=True)\n",
       "          )\n",
       "          (conv2): ConvBlock(\n",
       "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (activ): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (final_pool): AvgPool2d(kernel_size=8, stride=1, padding=0)\n",
       "  )\n",
       "  (output): Linear(in_features=64, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "\n",
    "# create loss function\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# get dataset \n",
    "train_loader, test_loader = getData(train_bs=20, train_length=0.02)\n",
    "\n",
    "model = model.cuda()\n",
    "\n",
    "# for illustrate, we only use one batch to do the tutorial\n",
    "for inputs, targets in train_loader:\n",
    "    break;\n",
    "print(len(train_loader))    \n",
    "print(len(inputs))\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Files already downloaded and verified\n",
      "50\n",
      "20\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "# create the hessian computation module\n",
    "hessian_comp = hessian_with_activation(model, criterion, dataloader=train_loader, cuda=True)\n",
    "hessian_comp.insert_hook(\"conv\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "# v = hessian_comp.get_activ_rand_v()\n",
    "hessian_comp.get_activ_rand_v(show_layer=True, dont_reset=True)\n",
    "for layer in hessian_comp.activation_grads.keys():\n",
    "    has_grad = hessian_comp.activation_grads[layer][0] #.require_grad()\n",
    "    # print(dir(has_grad))\n",
    "    if (has_grad is not None):\n",
    "        print(f\"*** {layer} : {has_grad.grad_fn}\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "append features.stage1.unit1.body.conv1.conv, active size : torch.Size([20, 16, 32, 32]), active grad size : torch.Size([20, 16, 32, 32])\n",
      "append features.stage1.unit1.body.conv2.conv, active size : torch.Size([20, 16, 32, 32]), active grad size : torch.Size([20, 16, 32, 32])\n",
      "append features.stage1.unit2.body.conv1.conv, active size : torch.Size([20, 16, 32, 32]), active grad size : torch.Size([20, 16, 32, 32])\n",
      "append features.stage1.unit2.body.conv2.conv, active size : torch.Size([20, 16, 32, 32]), active grad size : torch.Size([20, 16, 32, 32])\n",
      "append features.stage1.unit3.body.conv1.conv, active size : torch.Size([20, 16, 32, 32]), active grad size : torch.Size([20, 16, 32, 32])\n",
      "append features.stage1.unit3.body.conv2.conv, active size : torch.Size([20, 16, 32, 32]), active grad size : torch.Size([20, 16, 32, 32])\n",
      "append features.stage2.unit1.identity_conv.conv, active size : torch.Size([20, 16, 32, 32]), active grad size : torch.Size([20, 16, 32, 32])\n",
      "append features.stage2.unit1.body.conv1.conv, active size : torch.Size([20, 16, 32, 32]), active grad size : torch.Size([20, 16, 32, 32])\n",
      "append features.stage2.unit1.body.conv2.conv, active size : torch.Size([20, 32, 16, 16]), active grad size : torch.Size([20, 32, 16, 16])\n",
      "append features.stage2.unit2.body.conv1.conv, active size : torch.Size([20, 32, 16, 16]), active grad size : torch.Size([20, 32, 16, 16])\n",
      "append features.stage2.unit2.body.conv2.conv, active size : torch.Size([20, 32, 16, 16]), active grad size : torch.Size([20, 32, 16, 16])\n",
      "append features.stage2.unit3.body.conv1.conv, active size : torch.Size([20, 32, 16, 16]), active grad size : torch.Size([20, 32, 16, 16])\n",
      "append features.stage2.unit3.body.conv2.conv, active size : torch.Size([20, 32, 16, 16]), active grad size : torch.Size([20, 32, 16, 16])\n",
      "append features.stage3.unit1.identity_conv.conv, active size : torch.Size([20, 32, 16, 16]), active grad size : torch.Size([20, 32, 16, 16])\n",
      "append features.stage3.unit1.body.conv1.conv, active size : torch.Size([20, 32, 16, 16]), active grad size : torch.Size([20, 32, 16, 16])\n",
      "append features.stage3.unit1.body.conv2.conv, active size : torch.Size([20, 64, 8, 8]), active grad size : torch.Size([20, 64, 8, 8])\n",
      "append features.stage3.unit2.body.conv1.conv, active size : torch.Size([20, 64, 8, 8]), active grad size : torch.Size([20, 64, 8, 8])\n",
      "append features.stage3.unit2.body.conv2.conv, active size : torch.Size([20, 64, 8, 8]), active grad size : torch.Size([20, 64, 8, 8])\n",
      "append features.stage3.unit3.body.conv1.conv, active size : torch.Size([20, 64, 8, 8]), active grad size : torch.Size([20, 64, 8, 8])\n",
      "append features.stage3.unit3.body.conv2.conv, active size : torch.Size([20, 64, 8, 8]), active grad size : torch.Size([20, 64, 8, 8])\n",
      "*** features.stage3.unit3.body.conv2.conv : <CudnnConvolutionBackwardBackward object at 0x7ff68b171d30>\n",
      "*** features.stage3.unit3.body.conv1.conv : <CudnnConvolutionBackwardBackward object at 0x7ff68b1710a0>\n",
      "*** features.stage3.unit2.body.conv2.conv : <CudnnConvolutionBackwardBackward object at 0x7ff68b171f40>\n",
      "*** features.stage3.unit2.body.conv1.conv : <CudnnConvolutionBackwardBackward object at 0x7ff68b171b20>\n",
      "*** features.stage3.unit1.body.conv2.conv : <CudnnConvolutionBackwardBackward object at 0x7ff68b171670>\n",
      "*** features.stage3.unit1.body.conv1.conv : <CudnnConvolutionBackwardBackward object at 0x7ff68b171910>\n",
      "*** features.stage3.unit1.identity_conv : <NativeBatchNormBackwardBackward object at 0x7ff68b171730>\n",
      "*** features.stage3.unit1.identity_conv.conv : <CudnnConvolutionBackwardBackward object at 0x7ff68b171a90>\n",
      "*** features.stage2.unit3.body.conv2.conv : <CudnnConvolutionBackwardBackward object at 0x7ff7300a7fd0>\n",
      "*** features.stage2.unit3.body.conv1.conv : <CudnnConvolutionBackwardBackward object at 0x7ff7300a7610>\n",
      "*** features.stage2.unit2.body.conv2.conv : <CudnnConvolutionBackwardBackward object at 0x7ff68b1e7e80>\n",
      "*** features.stage2.unit2.body.conv1.conv : <CudnnConvolutionBackwardBackward object at 0x7ff68b228f40>\n",
      "*** features.stage2.unit1.body.conv2.conv : <CudnnConvolutionBackwardBackward object at 0x7ff73010dee0>\n",
      "*** features.stage2.unit1.body.conv1.conv : <CudnnConvolutionBackwardBackward object at 0x7ff6880590d0>\n",
      "*** features.stage2.unit1.identity_conv : <NativeBatchNormBackwardBackward object at 0x7ff688059190>\n",
      "*** features.stage2.unit1.identity_conv.conv : <CudnnConvolutionBackwardBackward object at 0x7ff688059250>\n",
      "*** features.stage1.unit3.body.conv2.conv : <CudnnConvolutionBackwardBackward object at 0x7ff688059310>\n",
      "*** features.stage1.unit3.body.conv1.conv : <CudnnConvolutionBackwardBackward object at 0x7ff6880593d0>\n",
      "*** features.stage1.unit2.body.conv2.conv : <CudnnConvolutionBackwardBackward object at 0x7ff688059490>\n",
      "*** features.stage1.unit2.body.conv1.conv : <CudnnConvolutionBackwardBackward object at 0x7ff688059550>\n",
      "*** features.stage1.unit1.body.conv2.conv : <CudnnConvolutionBackwardBackward object at 0x7ff688059610>\n",
      "*** features.stage1.unit1.body.conv1.conv : <CudnnConvolutionBackwardBackward object at 0x7ff6880596d0>\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "act_trace = hessian_comp.trace_activ(maxIter=50, tol=1e-6)\n",
    "print(act_trace[-2])\n",
    "print(act_trace[-1])"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_16288/1311904401.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mact_trace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhessian_comp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrace_activ\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaxIter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mact_trace\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mact_trace\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/thuako/PyHessian/pyhessian/hessian_with_activation.py\u001b[0m in \u001b[0;36mtrace_activ\u001b[0;34m(self, maxIter, tol)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull_dataset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m                 \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mActive_Hv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataloader_activation_hv_product\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactive_v\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    210\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m             \u001b[0mActive_trace_vhv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgroup_product\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mHv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mHv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mActive_Hv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactive_v\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/thuako/PyHessian/pyhessian/hessian_with_activation.py\u001b[0m in \u001b[0;36mdataloader_activation_hv_product\u001b[0;34m(self, active_v)\u001b[0m\n\u001b[1;32m    170\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mact\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactivation_grads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactive_v\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m                     Active_Hv_element = torch.autograd.grad(grad,\n\u001b[0m\u001b[1;32m    173\u001b[0m                                         \u001b[0mact\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m                                         \u001b[0mgrad_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/thuako/anaconda3/envs/torch17-cu10.2/lib/python3.8/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mgrad\u001b[0;34m(outputs, inputs, grad_outputs, retain_graph, create_graph, only_inputs, allow_unused)\u001b[0m\n\u001b[1;32m    200\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 202\u001b[0;31m     return Variable._execution_engine.run_backward(\n\u001b[0m\u001b[1;32m    203\u001b[0m         \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_outputs_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m         inputs, allow_unused)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "print((act_trace[-2]))\n",
    "print(act_trace[-1])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[27.796939849853516, 2.0737404823303223, 0.19290420413017273, 1.0326926708221436, 0.1409032791852951, 1.496253490447998, 0.08517349511384964, 0.19383658468723297, 0.5825191736221313, 0.10495015233755112, 0.9547169804573059, 0.09460827708244324, 2.080573320388794, 0.023283323273062706, 0.2941017150878906, 2.0656158924102783, 0.8748257756233215, 1.6801472902297974, 0.4482768177986145, 0.389938086271286]\n",
      "[11.472389221191406, 1.8090567588806152, 0.26039567589759827, 1.5163310766220093, 0.09185336530208588, 0.681473970413208, 0.08558680862188339, 0.06237340718507767, 1.7694450616836548, 0.08589757233858109, 1.5487838983535767, 0.18010348081588745, 2.0904734134674072, 0.03921247273683548, 0.3117707371711731, 1.1553516387939453, 1.6646945476531982, 2.620756149291992, 1.0674006938934326, 0.5741992592811584]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "trace = hessian_comp.trace(maxIter=1)\n",
    "print(\"The trace of this model is: %.4f\"%(np.mean(trace)))\n",
    "\n",
    "# print(hessian_comp.activations.keys())"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "check dataload hv product\n",
      "The trace of this model is: 296.7292\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "\n",
    "# # print(hessian_comp.activations.keys())\n",
    "# print((hessian_comp.activation_grads[\"features.stage1.unit1.body.conv1.conv\"][0][0].size()))\n",
    "# print((hessian_comp.activations[\"features.stage1.unit1.body.conv1.conv\"][0][0].size()))\n",
    "# # print((hessian_comp.activations[\"features.stage1.unit1.body.conv1.conv\"][0][0].grad))\n",
    "# print((hessian_comp.activations[\"features.stage1.unit1.body.conv1.conv\"][0][0]))\n",
    "# print((hessian_comp.activation_grads[\"features.stage1.unit1.body.conv1.conv\"][0][0]))\n",
    "# # print((hessian_comp.activation_grads[\"features.stage1.unit1.body.conv1.conv\"][0][0].grad_fn.next_functions))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "for layer in hessian_comp.activations.keys():\n",
    "    input_size = torch.randint_like(hessian_comp.activations[layer][0][0], high=2, device=\"cuda\").size()\n",
    "    if hessian_comp.activation_grads[layer][0][0] is not None:\n",
    "        grad_size = hessian_comp.activation_grads[layer][0][0].size()\n",
    "    else:\n",
    "        grad_size = 1\n",
    "    # print(type(hessian_comp.activation_grads[layer][i][0]))\n",
    "    if(input_size != grad_size):\n",
    "        print(f\"************* {layer} not equal!! ************\")\n",
    "        print( input_size, grad_size, \"\\n\\n\")\n",
    "    else:\n",
    "        print(f\"************* {layer} ************\")\n",
    "        print( input_size, \"\\n\\n\")\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "************* features.init_block.conv ************\n",
      "torch.Size([5, 3, 32, 32]) 1 \n",
      "\n",
      "\n",
      "************* features.stage1.unit1.body.conv1.conv ************\n",
      "torch.Size([5, 16, 32, 32]) \n",
      "\n",
      "\n",
      "************* features.stage1.unit1.body.conv2.conv ************\n",
      "torch.Size([5, 16, 32, 32]) \n",
      "\n",
      "\n",
      "************* features.stage1.unit2.body.conv1.conv ************\n",
      "torch.Size([5, 16, 32, 32]) \n",
      "\n",
      "\n",
      "************* features.stage1.unit2.body.conv2.conv ************\n",
      "torch.Size([5, 16, 32, 32]) \n",
      "\n",
      "\n",
      "************* features.stage1.unit3.body.conv1.conv ************\n",
      "torch.Size([5, 16, 32, 32]) \n",
      "\n",
      "\n",
      "************* features.stage1.unit3.body.conv2.conv ************\n",
      "torch.Size([5, 16, 32, 32]) \n",
      "\n",
      "\n",
      "************* features.stage2.unit1.identity_conv.conv ************\n",
      "torch.Size([5, 16, 32, 32]) \n",
      "\n",
      "\n",
      "************* features.stage2.unit1.identity_conv ************\n",
      "torch.Size([5, 16, 32, 32]) torch.Size([5, 32, 16, 16]) \n",
      "\n",
      "\n",
      "************* features.stage2.unit1.body.conv1.conv ************\n",
      "torch.Size([5, 16, 32, 32]) \n",
      "\n",
      "\n",
      "************* features.stage2.unit1.body.conv2.conv ************\n",
      "torch.Size([5, 32, 16, 16]) \n",
      "\n",
      "\n",
      "************* features.stage2.unit2.body.conv1.conv ************\n",
      "torch.Size([5, 32, 16, 16]) \n",
      "\n",
      "\n",
      "************* features.stage2.unit2.body.conv2.conv ************\n",
      "torch.Size([5, 32, 16, 16]) \n",
      "\n",
      "\n",
      "************* features.stage2.unit3.body.conv1.conv ************\n",
      "torch.Size([5, 32, 16, 16]) \n",
      "\n",
      "\n",
      "************* features.stage2.unit3.body.conv2.conv ************\n",
      "torch.Size([5, 32, 16, 16]) \n",
      "\n",
      "\n",
      "************* features.stage3.unit1.identity_conv.conv ************\n",
      "torch.Size([5, 32, 16, 16]) \n",
      "\n",
      "\n",
      "************* features.stage3.unit1.identity_conv ************\n",
      "torch.Size([5, 32, 16, 16]) torch.Size([5, 64, 8, 8]) \n",
      "\n",
      "\n",
      "************* features.stage3.unit1.body.conv1.conv ************\n",
      "torch.Size([5, 32, 16, 16]) \n",
      "\n",
      "\n",
      "************* features.stage3.unit1.body.conv2.conv ************\n",
      "torch.Size([5, 64, 8, 8]) \n",
      "\n",
      "\n",
      "************* features.stage3.unit2.body.conv1.conv ************\n",
      "torch.Size([5, 64, 8, 8]) \n",
      "\n",
      "\n",
      "************* features.stage3.unit2.body.conv2.conv ************\n",
      "torch.Size([5, 64, 8, 8]) \n",
      "\n",
      "\n",
      "************* features.stage3.unit3.body.conv1.conv ************\n",
      "torch.Size([5, 64, 8, 8]) \n",
      "\n",
      "\n",
      "************* features.stage3.unit3.body.conv2.conv ************\n",
      "torch.Size([5, 64, 8, 8]) \n",
      "\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "\"\"\"\n",
    "hessian_comp.activations[\"features.stage3.unit2.activ\"] are saved inputs of each layer\n",
    "while executing trace and dataload_hv_product for loop. \n",
    "They listed by trace and dataload_hv_product for loop.\n",
    "\n",
    "Dim 1 of hessian_comp.activations[\"features.stage3.unit2.activ\"][0] means batch.\n",
    "\"\"\"\n",
    "# v = torch.randint_like(hessian_comp.activations[\"features.stage1.unit1.body.conv1.conv\"][0][0], high=2, device=\"cuda\")\n",
    "rand_vs = []\n",
    "activ_grads = []\n",
    "activs = []\n",
    "\n",
    "for layer in hessian_comp.activations.keys():\n",
    "    for i in range(len(hessian_comp.activations[layer])):\n",
    "        activ_element = hessian_comp.activations[layer][i][0]\n",
    "        grad_element = hessian_comp.activation_grads[layer][i][0]\n",
    "\n",
    "        if (grad_element is None):\n",
    "            continue\n",
    "        elif grad_element.size() != activ_element.size() :\n",
    "            continue\n",
    "        else:    \n",
    "            rand_vs.append(torch.randint_like(hessian_comp.activations[layer][i][0], high=2, device=\"cuda\"))\n",
    "            activ_grads.append(hessian_comp.activation_grads[layer][i][0])\n",
    "            activs.append(hessian_comp.activations[layer][i][0])\n",
    "\n",
    "\n",
    "Hv_list = []\n",
    "trace_list = []\n",
    "for (v, grad, activ) in zip(rand_vs, activ_grads, activs):\n",
    "    Hv = torch.autograd.grad(\n",
    "        grad, \n",
    "        activ, \n",
    "        grad_outputs=v, only_inputs=True, retain_graph=True)\n",
    "    Hv_list.append(Hv)\n",
    "    trace_list.append(group_product(Hv, v).cpu().item())\n",
    "\n",
    "print(trace_list)\n",
    "\n",
    "\n",
    "# Hv = torch.autograd.grad(\n",
    "#     hessian_comp.activation_grads[\"features.stage1.unit1.body.conv1.conv\"][0][0], \n",
    "#     hessian_comp.activations[\"features.stage1.unit1.body.conv1.conv\"][0][0], \n",
    "#     grad_outputs=v, only_inputs=True, retain_graph=False)\n",
    "\n",
    "\n",
    "\n",
    "# a = torch.autograd.grad(hessian_comp.activation_grads[\"features.stage3.unit2.activ\"][1][0], hessian_comp.activations[\"features.stage3.unit2.activ\"][1]) \n",
    "# print(hessian_comp.activations[\"features.stage3.unit2.activ\"][1].size())"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[0.2398936152458191, 0.2883727252483368, 0.06399604678153992, 2.021277904510498, 0.024379881098866463, 2.3017399311065674, 0.05182919651269913, 0.07555367797613144, 0.4853941798210144, 0.007302280515432358, 0.8529448509216309, 0.2646264433860779, 21.458599090576172, 0.010562198236584663, 0.03980473428964615, 3.2707457542419434, 1.180624008178711, 5.310753345489502, 2.88645339012146, 5.8211669921875]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "layer1 = \"features.stage1.unit1.body.conv1.conv\"\n",
    "\n",
    "tmp_v = torch.randint_like(hessian_comp.activations[layer1][0][0], high=2, device=\"cuda\")\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "layer2 = \"features.stage1.unit1.body.conv1.conv\"\n",
    "\n",
    "Hv = torch.autograd.grad(\n",
    "    hessian_comp.activation_grads[layer1][0][0], \n",
    "    hessian_comp.activations[layer2][0][0], \n",
    "    grad_outputs=tmp_v, only_inputs=True, retain_graph=True)\n",
    "\n",
    "\n",
    "\n",
    "print(group_product(Hv, tmp_v).cpu().item())\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.6590860486030579\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Example 1: Power Iteration with Numpy\n",
    "\n",
    "The following part shows how to use power iteration to get the top eigenvalue of a matrix without explicitly having access to it in numpy. We start by creating a random matrix B, compute its ground truth eigenvalues using numpy, and then compare the results with matrix-free power iteration (which does not need direct access to the matrix)."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "n = 10 # the matrix size\n",
    "\n",
    "# generate a random matrix\n",
    "A = np.random.randn(n, n)\n",
    "B = A @ A.T"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now let's use numpy to compute the ground truth eigenvalues. We will then check the results with this."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "# use np.eigs to get the top eigenvalue of B\n",
    "eigs, _ = np.linalg.eig(B)\n",
    "\n",
    "print(\"The top eigenvalue of B is %.4f\"%np.sort(eigs)[-1])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The top eigenvalue of B is 21.3926\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now let's try to comptue the top eigenvalue of B without explicitly accessing B. To do so, we will use a method called Power Iteration:\n",
    "\n",
    "https://en.wikipedia.org/wiki/Power_iteration\n",
    "\n",
    "The algorithm is very simple and efficiet to compute the top eigenvalue:\n",
    "$$v_{i+1} = \\frac{Bv_i}{\\|Bv_i\\|}.$$\n",
    "\n",
    "As such, we only need to have access to the *application* of B to a given vector $v_i$ and not the matrix B itself. This application is commonly referred to as *matvec* in literature."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "# use power iteration to get the top eigenvalue of B\n",
    "v = np.random.randn(n, 1)\n",
    "for i in range(40):\n",
    "    v = v / np.linalg.norm(v)\n",
    "    eig_power_iteration = v.T @ B @ v\n",
    "    print(\"Step %2d current estimated top eigvalue: %.4f\"%(i+1,eig_power_iteration))\n",
    "    v = B @ v\n",
    "print(\"Finished Power Iteration\\n\")\n",
    "print(\"Ground Truth Top Eigenvalue: %.4f\"%np.sort(eigs)[-1])\n",
    "print(\"Result with matrix-free Power Iteration: %.4f\"%eig_power_iteration)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Step  1 current estimated top eigvalue: 10.7443\n",
      "Step  2 current estimated top eigvalue: 19.2796\n",
      "Step  3 current estimated top eigvalue: 20.0942\n",
      "Step  4 current estimated top eigvalue: 20.5082\n",
      "Step  5 current estimated top eigvalue: 20.8005\n",
      "Step  6 current estimated top eigvalue: 21.0048\n",
      "Step  7 current estimated top eigvalue: 21.1427\n",
      "Step  8 current estimated top eigvalue: 21.2333\n",
      "Step  9 current estimated top eigvalue: 21.2918\n",
      "Step 10 current estimated top eigvalue: 21.3291\n",
      "Step 11 current estimated top eigvalue: 21.3527\n",
      "Step 12 current estimated top eigvalue: 21.3676\n",
      "Step 13 current estimated top eigvalue: 21.3770\n",
      "Step 14 current estimated top eigvalue: 21.3828\n",
      "Step 15 current estimated top eigvalue: 21.3865\n",
      "Step 16 current estimated top eigvalue: 21.3888\n",
      "Step 17 current estimated top eigvalue: 21.3902\n",
      "Step 18 current estimated top eigvalue: 21.3911\n",
      "Step 19 current estimated top eigvalue: 21.3917\n",
      "Step 20 current estimated top eigvalue: 21.3920\n",
      "Step 21 current estimated top eigvalue: 21.3922\n",
      "Step 22 current estimated top eigvalue: 21.3924\n",
      "Step 23 current estimated top eigvalue: 21.3925\n",
      "Step 24 current estimated top eigvalue: 21.3925\n",
      "Step 25 current estimated top eigvalue: 21.3925\n",
      "Step 26 current estimated top eigvalue: 21.3926\n",
      "Step 27 current estimated top eigvalue: 21.3926\n",
      "Step 28 current estimated top eigvalue: 21.3926\n",
      "Step 29 current estimated top eigvalue: 21.3926\n",
      "Step 30 current estimated top eigvalue: 21.3926\n",
      "Step 31 current estimated top eigvalue: 21.3926\n",
      "Step 32 current estimated top eigvalue: 21.3926\n",
      "Step 33 current estimated top eigvalue: 21.3926\n",
      "Step 34 current estimated top eigvalue: 21.3926\n",
      "Step 35 current estimated top eigvalue: 21.3926\n",
      "Step 36 current estimated top eigvalue: 21.3926\n",
      "Step 37 current estimated top eigvalue: 21.3926\n",
      "Step 38 current estimated top eigvalue: 21.3926\n",
      "Step 39 current estimated top eigvalue: 21.3926\n",
      "Step 40 current estimated top eigvalue: 21.3926\n",
      "Finished Power Iteration\n",
      "\n",
      "Ground Truth Top Eigenvalue: 21.3926\n",
      "Result with matrix-free Power Iteration: 21.3926\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "As you can see the result of the power iteration and the one we got from numpy match very well.\n",
    "\n",
    "We can apply the same techinique for neural networks as well, and in particular use it to compute eigenvalues of Hessian!\n",
    "\n",
    "Importantly there has been a lot of misconception that we can not use Hessian for real world applications since\n",
    "we need to explicitly form it. Next you will see that this is not correct."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Example 2: Power Iteration for NN Hessian"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "# get the model \n",
    "model = ptcv_get_model(\"resnet20_cifar10\", pretrained=True)\n",
    "# change the model to eval mode to disable running stats upate\n",
    "model.eval()\n",
    "\n",
    "# create loss function\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# get dataset \n",
    "train_loader, test_loader = getData()\n",
    "\n",
    "# for illustrate, we only use one batch to do the tutorial\n",
    "for inputs, targets in train_loader:\n",
    "    break\n",
    "\n",
    "# we use cuda to make the computation fast\n",
    "model = model.cuda()\n",
    "inputs, targets = inputs.cuda(), targets.cuda()\n",
    "\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "# create the hessian computation module\n",
    "hessian_comp = hessian(model, criterion, data=(inputs, targets), cuda=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "# Now let's compute the top eigenvalue. This only takes a few seconds.\n",
    "top_eigenvalues, top_eigenvector = hessian_comp.eigenvalues()\n",
    "print(\"The top Hessian eigenvalue of this model is %.4f\"%top_eigenvalues[-1])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The top Hessian eigenvalue of this model is 147.6936\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "# Now let's compute the top 2 eigenavlues and eigenvectors of the Hessian\n",
    "top_eigenvalues, top_eigenvector = hessian_comp.eigenvalues(top_n=2)\n",
    "print(\"The top two eigenvalues of this model are: %.4f %.4f\"% (top_eigenvalues[-1],top_eigenvalues[-2]))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The top two eigenvalues of this model are: 147.6954 125.3500\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The small difference between this top eigenvalue (195.4954) and the previous one (195.5897) is due to the small number of iterations that we used in Power iteration. You can remove this small difference by increasing the number of iterations for power iteration."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Example 2.1: Plot Loss Landscape\n",
    "\n",
    "We can use the Hessian eigenvectors/eigenvalues to analyze the flat/sharpness of the loss landscape of your model, and plot the loss landscape. We will show that this can be more informative than using random directions.\n",
    "\n",
    "To plot the loss landscape, we first compute the top Hessian eigenvector and then perturb the model parameters along that direction and measure the loss."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# get the top eigenvector\n",
    "top_eigenvalues, top_eigenvector = hessian_comp.eigenvalues()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# This is a simple function, that will allow us to perturb the model paramters and get the result\n",
    "def get_params(model_orig,  model_perb, direction, alpha):\n",
    "    for m_orig, m_perb, d in zip(model_orig.parameters(), model_perb.parameters(), direction):\n",
    "        m_perb.data = m_orig.data + alpha * d\n",
    "    return model_perb"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# lambda is a small scalar that we use to perturb the model parameters along the eigenvectors \n",
    "lams = np.linspace(-0.5, 0.5, 21).astype(np.float32)\n",
    "\n",
    "loss_list = []\n",
    "\n",
    "# create a copy of the model\n",
    "model_perb = ptcv_get_model(\"resnet20_cifar10\", pretrained=True)\n",
    "model_perb.eval()\n",
    "model_perb = model_perb.cuda()\n",
    "\n",
    "for lam in lams:\n",
    "    model_perb = get_params(model, model_perb, top_eigenvector[0], lam)\n",
    "    loss_list.append(criterion(model_perb(inputs), targets).item())\n",
    "\n",
    "plt.plot(lams, loss_list)\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Perturbation')\n",
    "plt.title('Loss landscape perturbed based on top Hessian eigenvector')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now let's compare this with a loss landscape computed based on perturbing the model parameters along a random direction."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from pyhessian.utils import normalization\n",
    "\n",
    "# generate random vector to do the loss plot\n",
    "\n",
    "v = [torch.randn_like(p) for p in model.parameters()]\n",
    "v = normalization(v)\n",
    "\n",
    "\n",
    "# used to perturb your model \n",
    "lams = np.linspace(-0.5, 0.5, 21).astype(np.float32)\n",
    "\n",
    "loss_list = []\n",
    "\n",
    "# create a copy of the model\n",
    "model_perb = ptcv_get_model(\"resnet20_cifar10\", pretrained=True)\n",
    "model_perb.eval()\n",
    "model_perb = model_perb.cuda()\n",
    "\n",
    "for lam in lams: \n",
    "    model_perb = get_params(model, model_perb, v, lam)\n",
    "    loss_list.append(criterion(model_perb(inputs), targets).item())\n",
    "\n",
    "plt.plot(lams, loss_list)\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Perturbation')\n",
    "plt.title('Loss landscape perturbed based on a random direction')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Note how different the loss landscape looks. In particular note that there is almost no change in the loss value (see the small scale of the y-axis). This is expected, since for a converged NN, many of the directions are typically degenarate (i.e. they are flat)."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can also use gradient direction to perturb the model. While gradient is better than random vector, but it is not possible to use it to plot 3D loss landscape since you will need more than one direction. However, you can use top 2 Hessian vectors instead for that scenario."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from pyhessian.utils import normalization\n",
    "\n",
    "\n",
    "# used to perturb your model \n",
    "lams = np.linspace(-0.5, 0.5, 21).astype(np.float32)\n",
    "\n",
    "loss_list = []\n",
    "\n",
    "# create a copy of the model\n",
    "model_perb = ptcv_get_model(\"resnet20_cifar10\", pretrained=True)\n",
    "model_perb.eval()\n",
    "model_perb = model_perb.cuda()\n",
    "\n",
    "# generate gradient vector to do the loss plot\n",
    "loss = criterion(model_perb(inputs), targets)\n",
    "loss.backward()\n",
    "\n",
    "v = [p.grad.data for p in model_perb.parameters()]\n",
    "v = normalization(v)\n",
    "model_perb.zero_grad()\n",
    "\n",
    "\n",
    "for lam in lams: \n",
    "    model_perb = get_params(model, model_perb, v, lam)\n",
    "    loss_list.append(criterion(model_perb(inputs), targets).item())\n",
    "\n",
    "plt.plot(lams, loss_list)\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Perturbation')\n",
    "plt.title('Loss landscape perturbed based on gradient direction')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Example 3: Hessian Trace/Diagonal\n",
    "We can also use randomized linear algebra to compute Hessian trace or approximate the Hessian diagonal with very little computational overhead. Let's first start with a numpy example, and then we will show results for a NN."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "n = 1000 # the matrix size\n",
    "\n",
    "# generate the matrix\n",
    "A = np.random.randn(n, n)\n",
    "B = A @ A.T"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Direct get the trace \n",
    "trace_B_np = np.matrix.trace(B)\n",
    "print(\"The trace of B is: %.4f\"%trace_B_np)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can approximate the above by using Hutchinson Method. It is very similar to power iteration:\n",
    "\n",
    "$$Tr(B) = \\mathbb{E}[v^TBv],$$\n",
    "$$Diag(B) = \\mathbb{E}[v \\bigodot Bv].$$\n",
    "\n",
    "It can be proved that the above expectation converges with smallest variance to the trace if we use Rademacher random numbers (+/-1). In practice you can also use Gaussian random vectors as well."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# use Hutchinson method to get the trace of B\n",
    "trace_list = []\n",
    "\n",
    "for i in range(20):\n",
    "    v = np.random.randint(2, size=n) \n",
    "    v = v.reshape(n, 1) * 2 - 1 # Create Rademacher random numbers\n",
    "    trace_list.append(v.T @ B @ v)\n",
    "    trace_B_hutchinson = np.mean(trace_list)\n",
    "    print(\"Step %.2d, Current estimated trace: %.1f relative error: %.1e\"\n",
    "          %(i+1, trace_B_hutchinson, (trace_B_hutchinson - trace_B_np) / trace_B_np))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "As you can see we can get a very accurate estimate of the trace. Next let's try to approximate the diagonal of B using the matrix-free Hutchinson's method."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# use Hutchinson method to get the diag of B\n",
    "diag_est = np.zeros([n, 1])\n",
    "diag_B_np = np.diag(B)\n",
    "for i in range(20):\n",
    "    v = np.random.randint(2, size=n)\n",
    "    v = v.reshape(n, 1) * 2 - 1\n",
    "    diag_est += np.multiply(v, (B @ v))\n",
    "    diag_est_err = np.mean(np.abs(diag_est.reshape(-1) / (i+1) - diag_B_np) / diag_B_np)\n",
    "    print(\"Step %.2d, the current average relative error %.1e:\"%(i+1,diag_est_err))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now let's repeate the above for computing the trace and diagonal of Hessian for ResNet20."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\n",
    "density_eigen, density_weight = hessian_comp.density()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "get_esd_plot(density_eigen, density_weight)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The above ESD plot is very interesting and shows that a lot of the eigenvalues of the Hessian are close to zero. This means that a lot of the directions along the loss landscape is almost flat. We expect this based on the loss landscape that we got above when we used a random direction. Another interesting observation is that there are several large Hessian outliers. The other very interesting finding, is that there are a lot of directions with slight negative curvature. This means that we still have not converged to a perfect local minimum that satisfies first and second order optimality conditions."
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "529b676378f5ce4a809e497ca9afd9ec1da906fe30e9bc4a134076287a791763"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.11 64-bit ('torch17-cu10.2': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}