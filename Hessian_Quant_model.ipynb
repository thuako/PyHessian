{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "Authors: Zhewei Yao <https://github.com/yaozhewei>, Amir Gholami <http://amirgholami.org/>\n",
    "\n",
    "\n",
    "This tutorial shows how to compute the Hessian information using (randomized) numerical linear algebra for both explicit Hessian (the matrix is given) as well as implicit Hessian (the matrix is ungiven).\n",
    "\n",
    "We'll start by doing the necessary imports:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "import numpy as np\n",
    "import torch \n",
    "from torchvision import datasets, transforms\n",
    "from utils import * # get the dataset\n",
    "from pyhessian import hessian\n",
    "from pyhessian.hessian_with_activation import hessian_with_activation # Hessian computation\n",
    "from density_plot import get_esd_plot # ESD plot\n",
    "from pytorchcv.model_provider import get_model as ptcv_get_model # model\n",
    "from pyhessian.utils import group_product\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.distributed as dist\n",
    "import torch.optim\n",
    "import torch.multiprocessing as mp\n",
    "import torch.utils.data\n",
    "import torch.utils.data.distributed\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.models as models\n",
    "\n",
    "from HAWQ.bit_config import *\n",
    "from HAWQ.utils import *\n",
    "\n",
    "# enable cuda devices\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "model_arch = 'resnet18'\n",
    "model_resume = '/home/thuako/PyHessian/HAWQ/save_model/resnet18/uniform18model_best.pth.tar'\n",
    "save_path = '~/PyHessian/HAWQ/save_model/pyhessian/'\n",
    "quant_scheme = 'uniform8'\n",
    "bias_bit = 32\n",
    "channel_wise = True\n",
    "act_range_momentum = -1\n",
    "weight_percentile = 0\n",
    "act_percentile = 1\n",
    "fix_BN = True\n",
    "fix_BN_threshold = None\n",
    "checkpoint_iter = 1\n",
    "fixed_point_quantization = False"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "\n",
    "quantize_arch_dict = {'resnet50': q_resnet50, 'resnet50b': q_resnet50,\n",
    "                      'resnet18': q_resnet18, 'resnet101': q_resnet101,\n",
    "                      'inceptionv3': q_inceptionv3,\n",
    "                      'mobilenetv2_w1': q_mobilenetv2_w1}\n",
    "\n",
    "quantize_arch = quantize_arch_dict[model_arch]          \n",
    "model = ptcv_get_model(model_arch, pretrained=False)\n",
    "model = quantize_arch(model)\n",
    "\n",
    "checkpoint = torch.load(model_resume)['state_dict']\n",
    "model_key_list = list(model.state_dict().keys())\n",
    "for key in model_key_list:\n",
    "    if 'num_batches_tracked' in key: model_key_list.remove(key)\n",
    "i = 0\n",
    "modified_dict = {}\n",
    "for key, value in checkpoint.items():\n",
    "    if 'scaling_factor' in key: continue\n",
    "    if 'num_batches_tracked' in key: continue\n",
    "    if 'weight_integer' in key: continue\n",
    "    if 'min' in key or 'max' in key: continue\n",
    "    modified_key = model_key_list[i]\n",
    "    modified_dict[modified_key] = value\n",
    "    i += 1\n",
    "\n",
    "bit_config = bit_config_dict[\"bit_config_\" + model_arch + \"_\" + quant_scheme]\n",
    "name_counter = 0\n",
    "\n",
    "for name, m in model.named_modules():\n",
    "    if name in bit_config.keys():\n",
    "        name_counter += 1\n",
    "        setattr(m, 'quant_mode', 'symmetric')\n",
    "        setattr(m, 'bias_bit', bias_bit)\n",
    "        setattr(m, 'quantize_bias', (bias_bit != 0))\n",
    "        setattr(m, 'per_channel', channel_wise)\n",
    "        setattr(m, 'act_percentile', act_percentile)\n",
    "        setattr(m, 'act_range_momentum', act_range_momentum)\n",
    "        setattr(m, 'weight_percentile', weight_percentile)\n",
    "        setattr(m, 'fix_flag', False)\n",
    "        setattr(m, 'fix_BN', fix_BN)\n",
    "        setattr(m, 'fix_BN_threshold', fix_BN_threshold)\n",
    "        setattr(m, 'training_BN_mode', fix_BN)\n",
    "        setattr(m, 'checkpoint_iter_threshold', checkpoint_iter)\n",
    "        setattr(m, 'save_path', save_path)\n",
    "        setattr(m, 'fixed_point_quantization', fixed_point_quantization)\n",
    "\n",
    "        if type(bit_config[name]) is tuple:\n",
    "            bitwidth = bit_config[name][0]\n",
    "            if bit_config[name][1] == 'hook':\n",
    "                m.register_forward_hook(hook_fn_forward)\n",
    "                global hook_keys\n",
    "                hook_keys.append(name)\n",
    "        else:\n",
    "            bitwidth = bit_config[name]\n",
    "\n",
    "        if hasattr(m, 'activation_bit'):\n",
    "            setattr(m, 'activation_bit', bitwidth)\n",
    "            if bitwidth == 4:\n",
    "                setattr(m, 'quant_mode', 'asymmetric')\n",
    "        else:\n",
    "            setattr(m, 'weight_bit', bitwidth)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "# for resnet18 \n",
    "# set model and data set\n",
    "dataset = \"imagenet\"\n",
    "dataset_dir = \"/ImageNet/dataset/imagenet\"\n",
    "\n",
    "# model = ptcv_get_model(\"resnet18\", pretrained=True)\n",
    "model.eval()\n",
    "model = model.cuda()\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "# for name, module in model.named_modules():\n",
    "#     print(name)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "# get dataset \n",
    "train_loader, test_loader = getData(name='imagenet', train_bs=40, train_length=0.00096, data_dir=dataset_dir)\n",
    "\n",
    "for inputs, targets in train_loader:\n",
    "    break;\n",
    "print(f\"train_loader size : {len(train_loader)}\\n \\\n",
    "input size : {len(inputs)}\") \n",
    "\n",
    "hessian_comp_resnet = hessian_with_activation(model, criterion, dataloader=train_loader, cuda=True)\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "train_loader size : 31\n",
      " input size : 40\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "weight_trace = hessian_comp_resnet.trace(maxIter=1,param_name='conv.weight' )\n",
    "np.mean(weight_trace, axis=0)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "trace had not been converge\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([-1330.01403809,  4634.32324219, -4970.03222656, -3347.58496094,\n",
       "       -5367.63818359, -3505.81005859,  5201.21630859,   593.97424316,\n",
       "        6201.81835938, -2027.17626953,   639.85101318, -3703.32641602,\n",
       "        1171.79919434, 15643.91796875, -5805.25878906, -4618.35351562,\n",
       "       26616.61914062, -3289.92871094,  5587.85009766, 14902.50292969])"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "for name, module in model.named_buffers():\n",
    "    if 'weight' in name:\n",
    "        print(dir(module))\n",
    "        print(module.grad_fn)\n",
    "        break\n",
    "print(model)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['T', '__abs__', '__add__', '__and__', '__array__', '__array_priority__', '__array_wrap__', '__bool__', '__class__', '__complex__', '__contains__', '__cuda_array_interface__', '__deepcopy__', '__delattr__', '__delitem__', '__dict__', '__dir__', '__div__', '__doc__', '__eq__', '__float__', '__floordiv__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__gt__', '__hash__', '__iadd__', '__iand__', '__idiv__', '__ifloordiv__', '__ilshift__', '__imul__', '__index__', '__init__', '__init_subclass__', '__int__', '__invert__', '__ior__', '__ipow__', '__irshift__', '__isub__', '__iter__', '__itruediv__', '__ixor__', '__le__', '__len__', '__long__', '__lshift__', '__lt__', '__matmul__', '__mod__', '__module__', '__mul__', '__ne__', '__neg__', '__new__', '__nonzero__', '__or__', '__pow__', '__radd__', '__rdiv__', '__reduce__', '__reduce_ex__', '__repr__', '__reversed__', '__rfloordiv__', '__rmul__', '__rpow__', '__rshift__', '__rsub__', '__rtruediv__', '__setattr__', '__setitem__', '__setstate__', '__sizeof__', '__str__', '__sub__', '__subclasshook__', '__torch_function__', '__truediv__', '__weakref__', '__xor__', '_backward_hooks', '_base', '_cdata', '_coalesced_', '_dimI', '_dimV', '_grad', '_grad_fn', '_indices', '_is_view', '_make_subclass', '_nnz', '_update_names', '_values', '_version', 'abs', 'abs_', 'absolute', 'absolute_', 'acos', 'acos_', 'acosh', 'acosh_', 'add', 'add_', 'addbmm', 'addbmm_', 'addcdiv', 'addcdiv_', 'addcmul', 'addcmul_', 'addmm', 'addmm_', 'addmv', 'addmv_', 'addr', 'addr_', 'align_as', 'align_to', 'all', 'allclose', 'amax', 'amin', 'angle', 'any', 'apply_', 'arccos', 'arccos_', 'arccosh', 'arccosh_', 'arcsin', 'arcsin_', 'arcsinh', 'arcsinh_', 'arctan', 'arctan_', 'arctanh', 'arctanh_', 'argmax', 'argmin', 'argsort', 'as_strided', 'as_strided_', 'as_subclass', 'asin', 'asin_', 'asinh', 'asinh_', 'atan', 'atan2', 'atan2_', 'atan_', 'atanh', 'atanh_', 'backward', 'baddbmm', 'baddbmm_', 'bernoulli', 'bernoulli_', 'bfloat16', 'bincount', 'bitwise_and', 'bitwise_and_', 'bitwise_not', 'bitwise_not_', 'bitwise_or', 'bitwise_or_', 'bitwise_xor', 'bitwise_xor_', 'bmm', 'bool', 'byte', 'cauchy_', 'ceil', 'ceil_', 'char', 'cholesky', 'cholesky_inverse', 'cholesky_solve', 'chunk', 'clamp', 'clamp_', 'clamp_max', 'clamp_max_', 'clamp_min', 'clamp_min_', 'clip', 'clip_', 'clone', 'coalesce', 'conj', 'contiguous', 'copy_', 'cos', 'cos_', 'cosh', 'cosh_', 'count_nonzero', 'cpu', 'cross', 'cuda', 'cummax', 'cummin', 'cumprod', 'cumsum', 'data', 'data_ptr', 'deg2rad', 'deg2rad_', 'dense_dim', 'dequantize', 'det', 'detach', 'detach_', 'device', 'diag', 'diag_embed', 'diagflat', 'diagonal', 'digamma', 'digamma_', 'dim', 'dist', 'div', 'div_', 'divide', 'divide_', 'dot', 'double', 'dtype', 'eig', 'element_size', 'eq', 'eq_', 'equal', 'erf', 'erf_', 'erfc', 'erfc_', 'erfinv', 'erfinv_', 'exp', 'exp2', 'exp2_', 'exp_', 'expand', 'expand_as', 'expm1', 'expm1_', 'exponential_', 'fft', 'fill_', 'fill_diagonal_', 'fix', 'fix_', 'flatten', 'flip', 'fliplr', 'flipud', 'float', 'floor', 'floor_', 'floor_divide', 'floor_divide_', 'fmod', 'fmod_', 'frac', 'frac_', 'gather', 'gcd', 'gcd_', 'ge', 'ge_', 'geometric_', 'geqrf', 'ger', 'get_device', 'grad', 'grad_fn', 'greater', 'greater_', 'greater_equal', 'greater_equal_', 'gt', 'gt_', 'half', 'hardshrink', 'has_names', 'heaviside', 'heaviside_', 'histc', 'hypot', 'hypot_', 'i0', 'i0_', 'ifft', 'imag', 'index_add', 'index_add_', 'index_copy', 'index_copy_', 'index_fill', 'index_fill_', 'index_put', 'index_put_', 'index_select', 'indices', 'int', 'int_repr', 'inverse', 'irfft', 'is_coalesced', 'is_complex', 'is_contiguous', 'is_cuda', 'is_distributed', 'is_floating_point', 'is_leaf', 'is_meta', 'is_mkldnn', 'is_nonzero', 'is_pinned', 'is_quantized', 'is_same_size', 'is_set_to', 'is_shared', 'is_signed', 'is_sparse', 'isclose', 'isfinite', 'isinf', 'isnan', 'isneginf', 'isposinf', 'isreal', 'istft', 'item', 'kthvalue', 'layout', 'lcm', 'lcm_', 'le', 'le_', 'lerp', 'lerp_', 'less', 'less_', 'less_equal', 'less_equal_', 'lgamma', 'lgamma_', 'log', 'log10', 'log10_', 'log1p', 'log1p_', 'log2', 'log2_', 'log_', 'log_normal_', 'log_softmax', 'logaddexp', 'logaddexp2', 'logcumsumexp', 'logdet', 'logical_and', 'logical_and_', 'logical_not', 'logical_not_', 'logical_or', 'logical_or_', 'logical_xor', 'logical_xor_', 'logit', 'logit_', 'logsumexp', 'long', 'lstsq', 'lt', 'lt_', 'lu', 'lu_solve', 'map2_', 'map_', 'masked_fill', 'masked_fill_', 'masked_scatter', 'masked_scatter_', 'masked_select', 'matmul', 'matrix_exp', 'matrix_power', 'max', 'maximum', 'mean', 'median', 'min', 'minimum', 'mm', 'mode', 'movedim', 'mul', 'mul_', 'multinomial', 'multiply', 'multiply_', 'mv', 'mvlgamma', 'mvlgamma_', 'name', 'names', 'nanquantile', 'nansum', 'narrow', 'narrow_copy', 'ndim', 'ndimension', 'ne', 'ne_', 'neg', 'neg_', 'negative', 'negative_', 'nelement', 'new', 'new_empty', 'new_full', 'new_ones', 'new_tensor', 'new_zeros', 'nextafter', 'nextafter_', 'nonzero', 'norm', 'normal_', 'not_equal', 'not_equal_', 'numel', 'numpy', 'orgqr', 'ormqr', 'outer', 'output_nr', 'permute', 'pin_memory', 'pinverse', 'polygamma', 'polygamma_', 'pow', 'pow_', 'prelu', 'prod', 'put_', 'q_per_channel_axis', 'q_per_channel_scales', 'q_per_channel_zero_points', 'q_scale', 'q_zero_point', 'qr', 'qscheme', 'quantile', 'rad2deg', 'rad2deg_', 'random_', 'real', 'reciprocal', 'reciprocal_', 'record_stream', 'refine_names', 'register_hook', 'reinforce', 'relu', 'relu_', 'remainder', 'remainder_', 'rename', 'rename_', 'renorm', 'renorm_', 'repeat', 'repeat_interleave', 'requires_grad', 'requires_grad_', 'reshape', 'reshape_as', 'resize', 'resize_', 'resize_as', 'resize_as_', 'retain_grad', 'rfft', 'roll', 'rot90', 'round', 'round_', 'rsqrt', 'rsqrt_', 'scatter', 'scatter_', 'scatter_add', 'scatter_add_', 'select', 'set_', 'sgn', 'sgn_', 'shape', 'share_memory_', 'short', 'sigmoid', 'sigmoid_', 'sign', 'sign_', 'signbit', 'sin', 'sin_', 'sinh', 'sinh_', 'size', 'slogdet', 'smm', 'softmax', 'solve', 'sort', 'sparse_dim', 'sparse_mask', 'sparse_resize_', 'sparse_resize_and_clear_', 'split', 'split_with_sizes', 'sqrt', 'sqrt_', 'square', 'square_', 'squeeze', 'squeeze_', 'sspaddmm', 'std', 'stft', 'storage', 'storage_offset', 'storage_type', 'stride', 'sub', 'sub_', 'subtract', 'subtract_', 'sum', 'sum_to_size', 'svd', 'symeig', 't', 't_', 'take', 'tan', 'tan_', 'tanh', 'tanh_', 'to', 'to_dense', 'to_mkldnn', 'to_sparse', 'tolist', 'topk', 'trace', 'transpose', 'transpose_', 'triangular_solve', 'tril', 'tril_', 'triu', 'triu_', 'true_divide', 'true_divide_', 'trunc', 'trunc_', 'type', 'type_as', 'unbind', 'unflatten', 'unfold', 'uniform_', 'unique', 'unique_consecutive', 'unsafe_chunk', 'unsafe_split', 'unsafe_split_with_sizes', 'unsqueeze', 'unsqueeze_', 'values', 'var', 'vdot', 'view', 'view_as', 'where', 'zero_']\n",
      "None\n",
      "Q_ResNet18(\n",
      "  (quant_input): QuantAct(activation_bit=8, full_precision_flag=False, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (quant_init_block_convbn): (QuantBnConv2d(\n",
      "    (conv): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "    (bn): BatchNorm2d(64, eps=1e-05, momentum=0.99, affine=True, track_running_stats=True)\n",
      "  ), weight_bit=8, bias_bit=32, groups=1, wt-channel-wise=True, wt-percentile=0, quant_mode=symmetric)\n",
      "  (quant_act_int32): QuantAct(activation_bit=16, full_precision_flag=False, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (pool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (act): ReLU()\n",
      "  (stage1.unit1): Q_ResBlockBn(\n",
      "    (quant_act): QuantAct(activation_bit=8, full_precision_flag=False, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (quant_convbn1): (QuantBnConv2d(\n",
      "      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.99, affine=True, track_running_stats=True)\n",
      "    ), weight_bit=8, bias_bit=32, groups=1, wt-channel-wise=True, wt-percentile=0, quant_mode=symmetric)\n",
      "    (quant_act1): QuantAct(activation_bit=8, full_precision_flag=False, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (quant_convbn2): (QuantBnConv2d(\n",
      "      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.99, affine=True, track_running_stats=True)\n",
      "    ), weight_bit=8, bias_bit=32, groups=1, wt-channel-wise=True, wt-percentile=0, quant_mode=symmetric)\n",
      "    (quant_act_int32): QuantAct(activation_bit=16, full_precision_flag=False, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  )\n",
      "  (stage1.unit2): Q_ResBlockBn(\n",
      "    (quant_act): QuantAct(activation_bit=8, full_precision_flag=False, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (quant_convbn1): (QuantBnConv2d(\n",
      "      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.99, affine=True, track_running_stats=True)\n",
      "    ), weight_bit=8, bias_bit=32, groups=1, wt-channel-wise=True, wt-percentile=0, quant_mode=symmetric)\n",
      "    (quant_act1): QuantAct(activation_bit=8, full_precision_flag=False, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (quant_convbn2): (QuantBnConv2d(\n",
      "      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.99, affine=True, track_running_stats=True)\n",
      "    ), weight_bit=8, bias_bit=32, groups=1, wt-channel-wise=True, wt-percentile=0, quant_mode=symmetric)\n",
      "    (quant_act_int32): QuantAct(activation_bit=16, full_precision_flag=False, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  )\n",
      "  (stage2.unit1): Q_ResBlockBn(\n",
      "    (quant_act): QuantAct(activation_bit=8, full_precision_flag=False, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (quant_convbn1): (QuantBnConv2d(\n",
      "      (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.99, affine=True, track_running_stats=True)\n",
      "    ), weight_bit=8, bias_bit=32, groups=1, wt-channel-wise=True, wt-percentile=0, quant_mode=symmetric)\n",
      "    (quant_act1): QuantAct(activation_bit=8, full_precision_flag=False, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (quant_convbn2): (QuantBnConv2d(\n",
      "      (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.99, affine=True, track_running_stats=True)\n",
      "    ), weight_bit=8, bias_bit=32, groups=1, wt-channel-wise=True, wt-percentile=0, quant_mode=symmetric)\n",
      "    (quant_identity_convbn): (QuantBnConv2d(\n",
      "      (conv): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.99, affine=True, track_running_stats=True)\n",
      "    ), weight_bit=8, bias_bit=32, groups=1, wt-channel-wise=True, wt-percentile=0, quant_mode=symmetric)\n",
      "    (quant_act_int32): QuantAct(activation_bit=16, full_precision_flag=False, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  )\n",
      "  (stage2.unit2): Q_ResBlockBn(\n",
      "    (quant_act): QuantAct(activation_bit=8, full_precision_flag=False, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (quant_convbn1): (QuantBnConv2d(\n",
      "      (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.99, affine=True, track_running_stats=True)\n",
      "    ), weight_bit=8, bias_bit=32, groups=1, wt-channel-wise=True, wt-percentile=0, quant_mode=symmetric)\n",
      "    (quant_act1): QuantAct(activation_bit=8, full_precision_flag=False, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (quant_convbn2): (QuantBnConv2d(\n",
      "      (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.99, affine=True, track_running_stats=True)\n",
      "    ), weight_bit=8, bias_bit=32, groups=1, wt-channel-wise=True, wt-percentile=0, quant_mode=symmetric)\n",
      "    (quant_act_int32): QuantAct(activation_bit=16, full_precision_flag=False, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  )\n",
      "  (stage3.unit1): Q_ResBlockBn(\n",
      "    (quant_act): QuantAct(activation_bit=8, full_precision_flag=False, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (quant_convbn1): (QuantBnConv2d(\n",
      "      (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(256, eps=1e-05, momentum=0.99, affine=True, track_running_stats=True)\n",
      "    ), weight_bit=8, bias_bit=32, groups=1, wt-channel-wise=True, wt-percentile=0, quant_mode=symmetric)\n",
      "    (quant_act1): QuantAct(activation_bit=8, full_precision_flag=False, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (quant_convbn2): (QuantBnConv2d(\n",
      "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(256, eps=1e-05, momentum=0.99, affine=True, track_running_stats=True)\n",
      "    ), weight_bit=8, bias_bit=32, groups=1, wt-channel-wise=True, wt-percentile=0, quant_mode=symmetric)\n",
      "    (quant_identity_convbn): (QuantBnConv2d(\n",
      "      (conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "      (bn): BatchNorm2d(256, eps=1e-05, momentum=0.99, affine=True, track_running_stats=True)\n",
      "    ), weight_bit=8, bias_bit=32, groups=1, wt-channel-wise=True, wt-percentile=0, quant_mode=symmetric)\n",
      "    (quant_act_int32): QuantAct(activation_bit=16, full_precision_flag=False, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  )\n",
      "  (stage3.unit2): Q_ResBlockBn(\n",
      "    (quant_act): QuantAct(activation_bit=8, full_precision_flag=False, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (quant_convbn1): (QuantBnConv2d(\n",
      "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(256, eps=1e-05, momentum=0.99, affine=True, track_running_stats=True)\n",
      "    ), weight_bit=8, bias_bit=32, groups=1, wt-channel-wise=True, wt-percentile=0, quant_mode=symmetric)\n",
      "    (quant_act1): QuantAct(activation_bit=8, full_precision_flag=False, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (quant_convbn2): (QuantBnConv2d(\n",
      "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(256, eps=1e-05, momentum=0.99, affine=True, track_running_stats=True)\n",
      "    ), weight_bit=8, bias_bit=32, groups=1, wt-channel-wise=True, wt-percentile=0, quant_mode=symmetric)\n",
      "    (quant_act_int32): QuantAct(activation_bit=16, full_precision_flag=False, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  )\n",
      "  (stage4.unit1): Q_ResBlockBn(\n",
      "    (quant_act): QuantAct(activation_bit=8, full_precision_flag=False, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (quant_convbn1): (QuantBnConv2d(\n",
      "      (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(512, eps=1e-05, momentum=0.99, affine=True, track_running_stats=True)\n",
      "    ), weight_bit=8, bias_bit=32, groups=1, wt-channel-wise=True, wt-percentile=0, quant_mode=symmetric)\n",
      "    (quant_act1): QuantAct(activation_bit=8, full_precision_flag=False, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (quant_convbn2): (QuantBnConv2d(\n",
      "      (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(512, eps=1e-05, momentum=0.99, affine=True, track_running_stats=True)\n",
      "    ), weight_bit=8, bias_bit=32, groups=1, wt-channel-wise=True, wt-percentile=0, quant_mode=symmetric)\n",
      "    (quant_identity_convbn): (QuantBnConv2d(\n",
      "      (conv): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "      (bn): BatchNorm2d(512, eps=1e-05, momentum=0.99, affine=True, track_running_stats=True)\n",
      "    ), weight_bit=8, bias_bit=32, groups=1, wt-channel-wise=True, wt-percentile=0, quant_mode=symmetric)\n",
      "    (quant_act_int32): QuantAct(activation_bit=16, full_precision_flag=False, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  )\n",
      "  (stage4.unit2): Q_ResBlockBn(\n",
      "    (quant_act): QuantAct(activation_bit=8, full_precision_flag=False, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (quant_convbn1): (QuantBnConv2d(\n",
      "      (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(512, eps=1e-05, momentum=0.99, affine=True, track_running_stats=True)\n",
      "    ), weight_bit=8, bias_bit=32, groups=1, wt-channel-wise=True, wt-percentile=0, quant_mode=symmetric)\n",
      "    (quant_act1): QuantAct(activation_bit=8, full_precision_flag=False, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "    (quant_convbn2): (QuantBnConv2d(\n",
      "      (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(512, eps=1e-05, momentum=0.99, affine=True, track_running_stats=True)\n",
      "    ), weight_bit=8, bias_bit=32, groups=1, wt-channel-wise=True, wt-percentile=0, quant_mode=symmetric)\n",
      "    (quant_act_int32): QuantAct(activation_bit=16, full_precision_flag=False, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  )\n",
      "  (final_pool): QuantAveragePool2d(\n",
      "    (final_pool): AvgPool2d(kernel_size=7, stride=1, padding=0)\n",
      "  )\n",
      "  (quant_act_output): QuantAct(activation_bit=8, full_precision_flag=False, quant_mode=symmetric, Act_min: 0.00, Act_max: 0.00)\n",
      "  (quant_output): (QuantLinear() weight_bit=8, full_precision_flag=False, quantize_fn=symmetric)\n",
      ")\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "device = hessian_comp_resnet.device\n",
    "num_data = 0  # count the number of datum points in the dataloader\n",
    "hessian_comp_resnet.insert_hook_quant_module(\"quant_convbn\")\n",
    "for inputs, targets in hessian_comp_resnet.data:\n",
    "    hessian_comp_resnet.model.zero_grad()\n",
    "\n",
    "    hessian_comp_resnet.reset_reg_active()\n",
    "\n",
    "    outputs = hessian_comp_resnet.model(inputs.to(device))\n",
    "    loss = hessian_comp_resnet.criterion(outputs, targets.to(device))\n",
    "    loss.backward(create_graph=True)\n",
    "    break\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "stage1.unit1.quant_convbn1 module hooked\n",
      "stage1.unit1.quant_convbn2 module hooked\n",
      "stage1.unit2.quant_convbn1 module hooked\n",
      "stage1.unit2.quant_convbn2 module hooked\n",
      "stage2.unit1.quant_convbn1 module hooked\n",
      "stage2.unit1.quant_convbn2 module hooked\n",
      "stage2.unit2.quant_convbn1 module hooked\n",
      "stage2.unit2.quant_convbn2 module hooked\n",
      "stage3.unit1.quant_convbn1 module hooked\n",
      "stage3.unit1.quant_convbn2 module hooked\n",
      "stage3.unit2.quant_convbn1 module hooked\n",
      "stage3.unit2.quant_convbn2 module hooked\n",
      "stage4.unit1.quant_convbn1 module hooked\n",
      "stage4.unit1.quant_convbn2 module hooked\n",
      "stage4.unit2.quant_convbn1 module hooked\n",
      "stage4.unit2.quant_convbn2 module hooked\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "\n",
    "for key in hessian_comp_resnet.activation_grads.keys():\n",
    "    print(f'********** {key} **********')\n",
    "    print((hessian_comp_resnet.activation_grads[key][0][0].grad_fn))\n",
    "    print((hessian_comp_resnet.activation_grads[key][0][0].grad_fn.next_functions))\n",
    "    print(hessian_comp_resnet.activations[key][0][0].grad_fn)\n",
    "\n",
    "# for name, params in hessian_comp_resnet.model.named_modules():\n",
    "#     if name[:-1].endswith('quant_convbn'):\n",
    "#         print(f\"{name}\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "********** stage4.unit2.quant_convbn2 **********\n",
      "<DivBackward0 object at 0x7fe185c18a90>\n",
      "((<CloneBackward object at 0x7fe0e3b4ed60>, 0), (None, 0))\n",
      "<MulBackward0 object at 0x7fe0e3b4ed60>\n",
      "********** stage4.unit2.quant_convbn1 **********\n",
      "<ThresholdBackwardBackward object at 0x7fe0e3b4e970>\n",
      "((<DivBackward0 object at 0x7fe0e3b4e9a0>, 0), (<MulBackward0 object at 0x7fe0e3b4ed00>, 0))\n",
      "<MulBackward0 object at 0x7fe0e3b4e9a0>\n",
      "********** stage4.unit1.quant_convbn2 **********\n",
      "<DivBackward0 object at 0x7fe0e3b4ebb0>\n",
      "((<CloneBackward object at 0x7fe0e3b4ed90>, 0), (None, 0))\n",
      "<MulBackward0 object at 0x7fe0e3b4ed90>\n",
      "********** stage4.unit1.quant_convbn1 **********\n",
      "<ThresholdBackwardBackward object at 0x7fe0e6d52b50>\n",
      "((<DivBackward0 object at 0x7fe0e6d52520>, 0), (<MulBackward0 object at 0x7fe0e6d52d30>, 0))\n",
      "<MulBackward0 object at 0x7fe0e6d52520>\n",
      "********** stage3.unit2.quant_convbn2 **********\n",
      "<DivBackward0 object at 0x7fe0e6d52b20>\n",
      "((<CloneBackward object at 0x7fe0e6d52d00>, 0), (None, 0))\n",
      "<MulBackward0 object at 0x7fe0e6d52d00>\n",
      "********** stage3.unit2.quant_convbn1 **********\n",
      "<ThresholdBackwardBackward object at 0x7fe0e6d52a90>\n",
      "((<DivBackward0 object at 0x7fe0e6d52850>, 0), (<MulBackward0 object at 0x7fe0e6d52ac0>, 0))\n",
      "<MulBackward0 object at 0x7fe0e6d52850>\n",
      "********** stage3.unit1.quant_convbn2 **********\n",
      "<DivBackward0 object at 0x7fe0e6d52790>\n",
      "((<CloneBackward object at 0x7fe0e6d52100>, 0), (None, 0))\n",
      "<MulBackward0 object at 0x7fe0e6d52100>\n",
      "********** stage3.unit1.quant_convbn1 **********\n",
      "<ThresholdBackwardBackward object at 0x7fe0e6d52340>\n",
      "((<DivBackward0 object at 0x7fe0e6d527c0>, 0), (<MulBackward0 object at 0x7fe0e6d52250>, 0))\n",
      "<MulBackward0 object at 0x7fe0e6d527c0>\n",
      "********** stage2.unit2.quant_convbn2 **********\n",
      "<DivBackward0 object at 0x7fe0e6d52a30>\n",
      "((<CloneBackward object at 0x7fe0e62f4730>, 0), (None, 0))\n",
      "<MulBackward0 object at 0x7fe0e62f4730>\n",
      "********** stage2.unit2.quant_convbn1 **********\n",
      "<ThresholdBackwardBackward object at 0x7fe0e62f42b0>\n",
      "((<DivBackward0 object at 0x7fe0e62f4430>, 0), (<MulBackward0 object at 0x7fe0e62f4220>, 0))\n",
      "<MulBackward0 object at 0x7fe0e62f4430>\n",
      "********** stage2.unit1.quant_convbn2 **********\n",
      "<DivBackward0 object at 0x7fe0e62f4bb0>\n",
      "((<CloneBackward object at 0x7fe0e62f4c40>, 0), (None, 0))\n",
      "<MulBackward0 object at 0x7fe0e62f4c40>\n",
      "********** stage2.unit1.quant_convbn1 **********\n",
      "<ThresholdBackwardBackward object at 0x7fe0e62f4d60>\n",
      "((<DivBackward0 object at 0x7fe0e62f4100>, 0), (<MulBackward0 object at 0x7fe0e62f4f10>, 0))\n",
      "<MulBackward0 object at 0x7fe0e62f4100>\n",
      "********** stage1.unit2.quant_convbn2 **********\n",
      "<DivBackward0 object at 0x7fe0e62f4520>\n",
      "((<CloneBackward object at 0x7fe0e5069040>, 0), (None, 0))\n",
      "<MulBackward0 object at 0x7fe0e5069040>\n",
      "********** stage1.unit2.quant_convbn1 **********\n",
      "<ThresholdBackwardBackward object at 0x7fe0e5069250>\n",
      "((<DivBackward0 object at 0x7fe0e5069340>, 0), (<MulBackward0 object at 0x7fe0e5069370>, 0))\n",
      "<MulBackward0 object at 0x7fe0e5069340>\n",
      "********** stage1.unit1.quant_convbn2 **********\n",
      "<DivBackward0 object at 0x7fe0e5069550>\n",
      "((<CloneBackward object at 0x7fe0e5069640>, 0), (None, 0))\n",
      "<MulBackward0 object at 0x7fe0e5069640>\n",
      "********** stage1.unit1.quant_convbn1 **********\n",
      "<ThresholdBackwardBackward object at 0x7fe0e5069850>\n",
      "((<DivBackward0 object at 0x7fe0e5069940>, 0), (<MulBackward0 object at 0x7fe0e5069970>, 0))\n",
      "<MulBackward0 object at 0x7fe0e5069940>\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# hook and find activation trace\n",
    "hessian_comp_resnet.insert_hook(\"conv\")\n",
    "hessian_comp_resnet.check_reg_hook_size()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\n",
    "act_trace_resnet = hessian_comp_resnet.trace_activ(maxIter=1, tol=1e-3)\n",
    "np.mean(act_trace_resnet, axis=0)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "pyhessian = np.mean(weight_trace, axis=0)[1:]\n",
    "hawq = np.array([0.06857826, 0.03162379, 0.03298575, 0.01205663, 0.02222431, 0.00596336, 0.06931772, 0.00807129, 0.00372905, 0.00530698, 0.00209011, 0.00737569, 0.00210454, 0.00151197, 0.00158041,0.00078146, 0.00451841, 0.00098745, 0.00072944])\n",
    "\n",
    "print(len(pyhessian), len(hawq))\n",
    "print(pyhessian / hawq)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "19 19\n",
      "[ 6.28384714e+03 -1.28923168e+04 -2.09945935e+05  3.37263196e+05\n",
      "  2.85121360e+05  1.05976722e+06  5.16448765e+03  6.01798115e+05\n",
      " -8.99145786e+04  8.87246902e+05 -4.33565557e+06 -1.54747175e+05\n",
      "  1.27785208e+07 -7.81820771e+06  2.00849316e+06  2.67749379e+07\n",
      " -7.63025513e+05  1.86099652e+07  2.99477301e+07]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "param_count = []\n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "    if \"conv.weight\" in name:\n",
    "        param_count.append(len(param.view(-1)))\n",
    "(pyhessian / param_count[-1:]) "
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([ 0.00018265, -0.00017281, -0.00293529,  0.0017235 ,  0.00268581,\n",
       "        0.00267867,  0.00015174,  0.00205879, -0.00014212,  0.00199577,\n",
       "       -0.00384098, -0.00048377,  0.0113987 , -0.00501035,  0.00134542,\n",
       "        0.00886855, -0.00146131,  0.00778894,  0.00925915])"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "hessian_comp_resnet.show_hessian_layer()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "features.init_block.conv.conv.weight\n",
      "features.stage1.unit1.body.conv1.conv.weight\n",
      "features.stage1.unit1.body.conv2.conv.weight\n",
      "features.stage1.unit2.body.conv1.conv.weight\n",
      "features.stage1.unit2.body.conv2.conv.weight\n",
      "features.stage2.unit1.body.conv1.conv.weight\n",
      "features.stage2.unit1.body.conv2.conv.weight\n",
      "features.stage2.unit1.identity_conv.conv.weight\n",
      "features.stage2.unit2.body.conv1.conv.weight\n",
      "features.stage2.unit2.body.conv2.conv.weight\n",
      "features.stage3.unit1.body.conv1.conv.weight\n",
      "features.stage3.unit1.body.conv2.conv.weight\n",
      "features.stage3.unit1.identity_conv.conv.weight\n",
      "features.stage3.unit2.body.conv1.conv.weight\n",
      "features.stage3.unit2.body.conv2.conv.weight\n",
      "features.stage4.unit1.body.conv1.conv.weight\n",
      "features.stage4.unit1.body.conv2.conv.weight\n",
      "features.stage4.unit1.identity_conv.conv.weight\n",
      "features.stage4.unit2.body.conv1.conv.weight\n",
      "features.stage4.unit2.body.conv2.conv.weight\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "count = {\"conv.weight\": 0, \"bn.weight\": 0, \"bn.bias\":  0, \"features\": 0}\n",
    "\n",
    "weight_layer_list = []\n",
    "for (i, (name, p)) in enumerate(hessian_comp_resnet.model.named_parameters()):\n",
    "    print(f\"{name} gradient is {p.grad_fn}\")\n",
    "    for key in count.keys():\n",
    "        if key in name:\n",
    "            count[key] += 1\n",
    "                \n",
    "        \n",
    "for key in count.keys():\n",
    "    print(f\"the number of {key} : {count[key]}\")\n",
    "\n",
    "print(f\"the number of hessian : {len(np.mean(weight_trace, axis=0))}\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "features.init_block.conv.conv.weight gradient is None\n",
      "features.init_block.conv.bn.weight gradient is None\n",
      "features.init_block.conv.bn.bias gradient is None\n",
      "features.stage1.unit1.body.conv1.conv.weight gradient is None\n",
      "features.stage1.unit1.body.conv1.bn.weight gradient is None\n",
      "features.stage1.unit1.body.conv1.bn.bias gradient is None\n",
      "features.stage1.unit1.body.conv2.conv.weight gradient is None\n",
      "features.stage1.unit1.body.conv2.bn.weight gradient is None\n",
      "features.stage1.unit1.body.conv2.bn.bias gradient is None\n",
      "features.stage1.unit2.body.conv1.conv.weight gradient is None\n",
      "features.stage1.unit2.body.conv1.bn.weight gradient is None\n",
      "features.stage1.unit2.body.conv1.bn.bias gradient is None\n",
      "features.stage1.unit2.body.conv2.conv.weight gradient is None\n",
      "features.stage1.unit2.body.conv2.bn.weight gradient is None\n",
      "features.stage1.unit2.body.conv2.bn.bias gradient is None\n",
      "features.stage2.unit1.body.conv1.conv.weight gradient is None\n",
      "features.stage2.unit1.body.conv1.bn.weight gradient is None\n",
      "features.stage2.unit1.body.conv1.bn.bias gradient is None\n",
      "features.stage2.unit1.body.conv2.conv.weight gradient is None\n",
      "features.stage2.unit1.body.conv2.bn.weight gradient is None\n",
      "features.stage2.unit1.body.conv2.bn.bias gradient is None\n",
      "features.stage2.unit1.identity_conv.conv.weight gradient is None\n",
      "features.stage2.unit1.identity_conv.bn.weight gradient is None\n",
      "features.stage2.unit1.identity_conv.bn.bias gradient is None\n",
      "features.stage2.unit2.body.conv1.conv.weight gradient is None\n",
      "features.stage2.unit2.body.conv1.bn.weight gradient is None\n",
      "features.stage2.unit2.body.conv1.bn.bias gradient is None\n",
      "features.stage2.unit2.body.conv2.conv.weight gradient is None\n",
      "features.stage2.unit2.body.conv2.bn.weight gradient is None\n",
      "features.stage2.unit2.body.conv2.bn.bias gradient is None\n",
      "features.stage3.unit1.body.conv1.conv.weight gradient is None\n",
      "features.stage3.unit1.body.conv1.bn.weight gradient is None\n",
      "features.stage3.unit1.body.conv1.bn.bias gradient is None\n",
      "features.stage3.unit1.body.conv2.conv.weight gradient is None\n",
      "features.stage3.unit1.body.conv2.bn.weight gradient is None\n",
      "features.stage3.unit1.body.conv2.bn.bias gradient is None\n",
      "features.stage3.unit1.identity_conv.conv.weight gradient is None\n",
      "features.stage3.unit1.identity_conv.bn.weight gradient is None\n",
      "features.stage3.unit1.identity_conv.bn.bias gradient is None\n",
      "features.stage3.unit2.body.conv1.conv.weight gradient is None\n",
      "features.stage3.unit2.body.conv1.bn.weight gradient is None\n",
      "features.stage3.unit2.body.conv1.bn.bias gradient is None\n",
      "features.stage3.unit2.body.conv2.conv.weight gradient is None\n",
      "features.stage3.unit2.body.conv2.bn.weight gradient is None\n",
      "features.stage3.unit2.body.conv2.bn.bias gradient is None\n",
      "features.stage4.unit1.body.conv1.conv.weight gradient is None\n",
      "features.stage4.unit1.body.conv1.bn.weight gradient is None\n",
      "features.stage4.unit1.body.conv1.bn.bias gradient is None\n",
      "features.stage4.unit1.body.conv2.conv.weight gradient is None\n",
      "features.stage4.unit1.body.conv2.bn.weight gradient is None\n",
      "features.stage4.unit1.body.conv2.bn.bias gradient is None\n",
      "features.stage4.unit1.identity_conv.conv.weight gradient is None\n",
      "features.stage4.unit1.identity_conv.bn.weight gradient is None\n",
      "features.stage4.unit1.identity_conv.bn.bias gradient is None\n",
      "features.stage4.unit2.body.conv1.conv.weight gradient is None\n",
      "features.stage4.unit2.body.conv1.bn.weight gradient is None\n",
      "features.stage4.unit2.body.conv1.bn.bias gradient is None\n",
      "features.stage4.unit2.body.conv2.conv.weight gradient is None\n",
      "features.stage4.unit2.body.conv2.bn.weight gradient is None\n",
      "features.stage4.unit2.body.conv2.bn.bias gradient is None\n",
      "output.weight gradient is None\n",
      "output.bias gradient is None\n",
      "the number of conv.weight : 20\n",
      "the number of bn.weight : 20\n",
      "the number of bn.bias : 20\n",
      "the number of features : 60\n",
      "the number of hessian : 20\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "weight_trace = hessian_comp_resnet.trace(maxIter=50)\n",
    "np.mean(weight_trace, axis=0)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "trace had not been converge\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([ 2.71595064e+03,  8.71741765e+00,  2.62039937e+01,  3.64793158e+03,\n",
       "        4.74658755e+00,  6.00919633e-01,  1.37105965e+03, -9.40865991e-01,\n",
       "        5.33281157e+00,  1.64131633e+03, -5.24804253e-01,  1.09716395e+00,\n",
       "        6.97771637e+02,  1.34698081e+00, -1.11872495e+00,  1.70895995e+03,\n",
       "       -1.33548991e+00,  4.47255922e+00,  1.17322799e+03, -1.52370351e+00,\n",
       "        2.89366024e+00,  4.39872609e+02, -1.25825181e+00,  1.79194921e-01,\n",
       "        1.58911529e+03, -5.89528441e-03, -6.85732658e-01,  7.19000252e+02,\n",
       "        2.33258068e+00,  5.12466332e-01,  1.98001098e+03,  2.98390957e+00,\n",
       "        8.72554815e-02,  1.38419868e+03,  1.84380284e+00,  6.69318685e+00,\n",
       "        3.47149133e+02,  5.48378468e-01, -1.47029647e+00,  1.60556912e+03,\n",
       "       -1.89265554e-01,  6.95783268e-01,  1.07468449e+03,  1.29804430e+00,\n",
       "        1.51972714e+00,  2.47274337e+03,  2.63763887e+00,  1.21341769e+00,\n",
       "        2.22600354e+03,  4.98319585e-01, -6.70611072e-02,  7.62577498e+02,\n",
       "        4.47491714e-01,  6.08462400e-01,  2.74579423e+03,  6.33828760e+00,\n",
       "        4.35372606e+00,  2.23056023e+03,  2.38342956e-01,  2.17061395e-01,\n",
       "        6.85999280e+02,  8.48561153e-01])"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# get the model \n",
    "model = ptcv_get_model(\"resnet20_cifar10\", pretrained=True)\n",
    "model.eval()\n",
    "model = model.cuda()\n",
    "\n",
    "# create loss function\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# get dataset \n",
    "train_loader, test_loader = getData(train_bs=80, train_length=0.024)\n",
    "\n",
    "# for illustrate, we only use one batch to do the tutorial\n",
    "for inputs, targets in train_loader:\n",
    "    break;\n",
    "print(len(train_loader))    \n",
    "print(len(inputs))\n",
    "\n",
    "# change the model to eval mode to disable running stats upate\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# create the hessian computation module\n",
    "hessian_comp = hessian_with_activation(model, criterion, dataloader=train_loader, cuda=True)\n",
    "hessian_comp.insert_hook(\"conv\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "act_trace = hessian_comp.trace_activ(maxIter=100, tol=1e-3)\n",
    "np.mean(act_trace, axis=0)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "In 83th iteration, trace had been converge\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "array([12.90942681,  1.92099523,  0.22628432,  1.12419579,  0.1060052 ,\n",
       "        0.93684972,  0.13285358,  0.12223492,  0.92358128,  0.14782701,\n",
       "        1.02247512,  0.15254644,  1.81130452,  0.02953197,  0.2341992 ,\n",
       "        1.69802872,  1.14589175,  1.44514605,  0.73692089,  0.51901171])"
      ]
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Note how different the loss landscape looks. In particular note that there is almost no change in the loss value (see the small scale of the y-axis). This is expected, since for a converged NN, many of the directions are typically degenarate (i.e. they are flat)."
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a07942d7ea83692363db5dfc5da1c415492af6053fd8e4436b93cdbac81289b7"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.11 64-bit ('torch17-cu11.0': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}